{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292c7995-0d36-49da-ba08-0b05f66b1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from scipy.stats import ttest_ind, levene\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold,ShuffleSplit,cross_val_score,RepeatedKFold\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a235bbc0-3120-496c-a897-18d304a15313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LA = pd.read_csv(\"input/LA_total.csv\",index_col=0)\n",
    "data_XA = pd.read_csv(\"input/XA_total.csv\",index_col=0)\n",
    "\n",
    "\n",
    "data_LA_ = pd.DataFrame()\n",
    "columns_LA = data_LA.columns\n",
    "for col in columns_LA:\n",
    "    try:\n",
    "        df = data_LA[col].astype(np.float64)\n",
    "        data_LA_ = pd.concat([data_LA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "    \n",
    "data_XA_ = pd.DataFrame()\n",
    "columns_XA = data_XA.columns\n",
    "for col in columns_XA:\n",
    "    try:\n",
    "        df = data_XA[col].astype(np.float64)\n",
    "        data_XA_ = pd.concat([data_XA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "\n",
    "# 方差齐性\n",
    "index_ = []\n",
    "for col in data_LA_.columns:\n",
    "    if levene(data_LA_[col],data_XA_[col])[1] > 0.05:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col])[1] < 0.05:\n",
    "            index_.append(col)\n",
    "    else:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col],equal_var=False)[1] < 0.05:\n",
    "            index_.append(col)\n",
    "\n",
    "\n",
    "data_L_T = data_LA_[index_]\n",
    "data_X_T = data_XA_[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174e1e5d-6f5b-476e-b9f9-4141bce75599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MVI</th>\n",
       "      <th>diagnosticsImage-originalMean</th>\n",
       "      <th>diagnosticsImage-originalMinimum</th>\n",
       "      <th>diagnosticsMask-originalVoxelNum</th>\n",
       "      <th>originalshapeFlatness</th>\n",
       "      <th>originalshapeLeastAxisLength</th>\n",
       "      <th>originalshapeMaximum2DDiameterRow</th>\n",
       "      <th>originalshapeMaximum2DDiameterSlice</th>\n",
       "      <th>originalshapeMeshVolume</th>\n",
       "      <th>originalshapeMinorAxisLength</th>\n",
       "      <th>...</th>\n",
       "      <th>wavelet-LLLglszmGrayLevelNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmLowGrayLevelZoneEmphasis</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformityNormalized</th>\n",
       "      <th>wavelet-LLLglszmSmallAreaEmphasis</th>\n",
       "      <th>wavelet-LLLglszmZoneEntropy</th>\n",
       "      <th>wavelet-LLLglszmZonePercentage</th>\n",
       "      <th>wavelet-LLLngtdmCoarseness</th>\n",
       "      <th>wavelet-LLLngtdmContrast</th>\n",
       "      <th>wavelet-LLLngtdmStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-590.996050</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>0.567642</td>\n",
       "      <td>17.480034</td>\n",
       "      <td>31.824932</td>\n",
       "      <td>34.239088</td>\n",
       "      <td>7708.781387</td>\n",
       "      <td>22.177547</td>\n",
       "      <td>...</td>\n",
       "      <td>27.328657</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>158.450902</td>\n",
       "      <td>0.317537</td>\n",
       "      <td>0.580434</td>\n",
       "      <td>6.494470</td>\n",
       "      <td>0.264721</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.112960</td>\n",
       "      <td>2.505126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-664.262732</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>0.440898</td>\n",
       "      <td>14.373141</td>\n",
       "      <td>34.276051</td>\n",
       "      <td>32.240447</td>\n",
       "      <td>8627.979492</td>\n",
       "      <td>27.127836</td>\n",
       "      <td>...</td>\n",
       "      <td>32.483412</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>112.620853</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.524739</td>\n",
       "      <td>6.171855</td>\n",
       "      <td>0.221174</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.559084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X65</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-678.863086</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>12095.0</td>\n",
       "      <td>0.521147</td>\n",
       "      <td>32.076241</td>\n",
       "      <td>71.424541</td>\n",
       "      <td>70.037744</td>\n",
       "      <td>57577.086360</td>\n",
       "      <td>43.490283</td>\n",
       "      <td>...</td>\n",
       "      <td>132.707956</td>\n",
       "      <td>0.012702</td>\n",
       "      <td>236.119839</td>\n",
       "      <td>0.237784</td>\n",
       "      <td>0.489621</td>\n",
       "      <td>5.948185</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.109557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X58</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-648.246681</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.685351</td>\n",
       "      <td>9.026083</td>\n",
       "      <td>24.103604</td>\n",
       "      <td>11.623848</td>\n",
       "      <td>729.836266</td>\n",
       "      <td>9.988381</td>\n",
       "      <td>...</td>\n",
       "      <td>4.710145</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>25.231884</td>\n",
       "      <td>0.365679</td>\n",
       "      <td>0.613855</td>\n",
       "      <td>5.181363</td>\n",
       "      <td>0.392045</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>1.034368</td>\n",
       "      <td>9.291845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-600.984933</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.614269</td>\n",
       "      <td>7.908654</td>\n",
       "      <td>17.802055</td>\n",
       "      <td>12.827708</td>\n",
       "      <td>839.388805</td>\n",
       "      <td>11.355911</td>\n",
       "      <td>...</td>\n",
       "      <td>7.411765</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>57.250000</td>\n",
       "      <td>0.420956</td>\n",
       "      <td>0.673088</td>\n",
       "      <td>5.633501</td>\n",
       "      <td>0.521073</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>11.364464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-638.027673</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>17.108227</td>\n",
       "      <td>35.733521</td>\n",
       "      <td>28.381363</td>\n",
       "      <td>8521.587433</td>\n",
       "      <td>21.537387</td>\n",
       "      <td>...</td>\n",
       "      <td>59.316891</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>208.608371</td>\n",
       "      <td>0.311821</td>\n",
       "      <td>0.573856</td>\n",
       "      <td>5.860988</td>\n",
       "      <td>0.295756</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.740093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-620.813483</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>5249.0</td>\n",
       "      <td>0.573858</td>\n",
       "      <td>23.268326</td>\n",
       "      <td>41.748175</td>\n",
       "      <td>48.856055</td>\n",
       "      <td>19690.859380</td>\n",
       "      <td>30.373199</td>\n",
       "      <td>...</td>\n",
       "      <td>114.811057</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>480.682295</td>\n",
       "      <td>0.336377</td>\n",
       "      <td>0.600516</td>\n",
       "      <td>5.992634</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>0.198260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-539.902547</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.270528</td>\n",
       "      <td>8.809353</td>\n",
       "      <td>25.858086</td>\n",
       "      <td>14.502828</td>\n",
       "      <td>1664.852865</td>\n",
       "      <td>10.103964</td>\n",
       "      <td>...</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>88.804444</td>\n",
       "      <td>0.394686</td>\n",
       "      <td>0.650065</td>\n",
       "      <td>6.211085</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.935525</td>\n",
       "      <td>6.807361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-578.514587</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.410397</td>\n",
       "      <td>6.165698</td>\n",
       "      <td>17.414523</td>\n",
       "      <td>11.275838</td>\n",
       "      <td>598.382812</td>\n",
       "      <td>9.522956</td>\n",
       "      <td>...</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>15.192308</td>\n",
       "      <td>0.292160</td>\n",
       "      <td>0.555985</td>\n",
       "      <td>5.195350</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.035838</td>\n",
       "      <td>0.250684</td>\n",
       "      <td>4.360344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-639.387528</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000868</td>\n",
       "      <td>5.669270</td>\n",
       "      <td>96.106771</td>\n",
       "      <td>3.279435</td>\n",
       "      <td>...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.078011</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.863426</td>\n",
       "      <td>3.740602</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.243869</td>\n",
       "      <td>0.212977</td>\n",
       "      <td>14.239747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MVI  diagnosticsImage-originalMean  diagnosticsImage-originalMinimum  \\\n",
       "L35  0.0                    -590.996050                           -1024.0   \n",
       "L44  0.0                    -664.262732                           -1024.0   \n",
       "X65  1.0                    -678.863086                           -1024.0   \n",
       "X58  1.0                    -648.246681                           -1024.0   \n",
       "x20  1.0                    -600.984933                           -1024.0   \n",
       "..   ...                            ...                               ...   \n",
       "X34  1.0                    -638.027673                           -1024.0   \n",
       "L52  0.0                    -620.813483                           -1024.0   \n",
       "X15  1.0                    -539.902547                           -1024.0   \n",
       "L41  0.0                    -578.514587                           -1024.0   \n",
       "L2   0.0                    -639.387528                           -1024.0   \n",
       "\n",
       "     diagnosticsMask-originalVoxelNum  originalshapeFlatness  \\\n",
       "L35                            1885.0               0.567642   \n",
       "L44                            1908.0               0.440898   \n",
       "X65                           12095.0               0.521147   \n",
       "X58                             176.0               0.685351   \n",
       "x20                             261.0               0.614269   \n",
       "..                                ...                    ...   \n",
       "X34                            2262.0               0.428130   \n",
       "L52                            5249.0               0.573858   \n",
       "X15                             459.0               0.270528   \n",
       "L41                             168.0               0.410397   \n",
       "L2                               30.0               0.000000   \n",
       "\n",
       "     originalshapeLeastAxisLength  originalshapeMaximum2DDiameterRow  \\\n",
       "L35                     17.480034                          31.824932   \n",
       "L44                     14.373141                          34.276051   \n",
       "X65                     32.076241                          71.424541   \n",
       "X58                      9.026083                          24.103604   \n",
       "x20                      7.908654                          17.802055   \n",
       "..                            ...                                ...   \n",
       "X34                     17.108227                          35.733521   \n",
       "L52                     23.268326                          41.748175   \n",
       "X15                      8.809353                          25.858086   \n",
       "L41                      6.165698                          17.414523   \n",
       "L2                       0.000000                           9.000868   \n",
       "\n",
       "     originalshapeMaximum2DDiameterSlice  originalshapeMeshVolume  \\\n",
       "L35                            34.239088              7708.781387   \n",
       "L44                            32.240447              8627.979492   \n",
       "X65                            70.037744             57577.086360   \n",
       "X58                            11.623848               729.836266   \n",
       "x20                            12.827708               839.388805   \n",
       "..                                   ...                      ...   \n",
       "X34                            28.381363              8521.587433   \n",
       "L52                            48.856055             19690.859380   \n",
       "X15                            14.502828              1664.852865   \n",
       "L41                            11.275838               598.382812   \n",
       "L2                              5.669270                96.106771   \n",
       "\n",
       "     originalshapeMinorAxisLength  ...  \\\n",
       "L35                     22.177547  ...   \n",
       "L44                     27.127836  ...   \n",
       "X65                     43.490283  ...   \n",
       "X58                      9.988381  ...   \n",
       "x20                     11.355911  ...   \n",
       "..                            ...  ...   \n",
       "X34                     21.537387  ...   \n",
       "L52                     30.373199  ...   \n",
       "X15                     10.103964  ...   \n",
       "L41                      9.522956  ...   \n",
       "L2                       3.279435  ...   \n",
       "\n",
       "     wavelet-LLLglszmGrayLevelNonUniformity  \\\n",
       "L35                               27.328657   \n",
       "L44                               32.483412   \n",
       "X65                              132.707956   \n",
       "X58                                4.710145   \n",
       "x20                                7.411765   \n",
       "..                                      ...   \n",
       "X34                               59.316891   \n",
       "L52                              114.811057   \n",
       "X15                                8.760000   \n",
       "L41                                3.461538   \n",
       "L2                                 2.250000   \n",
       "\n",
       "     wavelet-LLLglszmLowGrayLevelZoneEmphasis  \\\n",
       "L35                                  0.005205   \n",
       "L44                                  0.018894   \n",
       "X65                                  0.012702   \n",
       "X58                                  0.031861   \n",
       "x20                                  0.010612   \n",
       "..                                        ...   \n",
       "X34                                  0.012227   \n",
       "L52                                  0.009208   \n",
       "X15                                  0.013163   \n",
       "L41                                  0.026416   \n",
       "L2                                   0.078011   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformity  \\\n",
       "L35                             158.450902   \n",
       "L44                             112.620853   \n",
       "X65                             236.119839   \n",
       "X58                              25.231884   \n",
       "x20                              57.250000   \n",
       "..                                     ...   \n",
       "X34                             208.608371   \n",
       "L52                             480.682295   \n",
       "X15                              88.804444   \n",
       "L41                              15.192308   \n",
       "L2                               17.000000   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformityNormalized  \\\n",
       "L35                                         0.317537   \n",
       "L44                                         0.266874   \n",
       "X65                                         0.237784   \n",
       "X58                                         0.365679   \n",
       "x20                                         0.420956   \n",
       "..                                               ...   \n",
       "X34                                         0.311821   \n",
       "L52                                         0.336377   \n",
       "X15                                         0.394686   \n",
       "L41                                         0.292160   \n",
       "L2                                          0.708333   \n",
       "\n",
       "     wavelet-LLLglszmSmallAreaEmphasis  wavelet-LLLglszmZoneEntropy  \\\n",
       "L35                           0.580434                     6.494470   \n",
       "L44                           0.524739                     6.171855   \n",
       "X65                           0.489621                     5.948185   \n",
       "X58                           0.613855                     5.181363   \n",
       "x20                           0.673088                     5.633501   \n",
       "..                                 ...                          ...   \n",
       "X34                           0.573856                     5.860988   \n",
       "L52                           0.600516                     5.992634   \n",
       "X15                           0.650065                     6.211085   \n",
       "L41                           0.555985                     5.195350   \n",
       "L2                            0.863426                     3.740602   \n",
       "\n",
       "     wavelet-LLLglszmZonePercentage  wavelet-LLLngtdmCoarseness  \\\n",
       "L35                        0.264721                    0.003280   \n",
       "L44                        0.221174                    0.004015   \n",
       "X65                        0.082100                    0.000596   \n",
       "X58                        0.392045                    0.013722   \n",
       "x20                        0.521073                    0.033755   \n",
       "..                              ...                         ...   \n",
       "X34                        0.295756                    0.003178   \n",
       "L52                        0.272242                    0.001339   \n",
       "X15                        0.490196                    0.007549   \n",
       "L41                        0.309524                    0.035838   \n",
       "L2                         0.800000                    0.243869   \n",
       "\n",
       "     wavelet-LLLngtdmContrast  wavelet-LLLngtdmStrength  \n",
       "L35                  0.112960                  2.505126  \n",
       "L44                  0.066445                  0.559084  \n",
       "X65                  0.014271                  0.109557  \n",
       "X58                  1.034368                  9.291845  \n",
       "x20                  0.192491                 11.364464  \n",
       "..                        ...                       ...  \n",
       "X34                  0.039251                  0.740093  \n",
       "L52                  0.059543                  0.198260  \n",
       "X15                  0.935525                  6.807361  \n",
       "L41                  0.250684                  4.360344  \n",
       "L2                   0.212977                 14.239747  \n",
       "\n",
       "[138 rows x 460 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_L_T,data_X_T])\n",
    "data = shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c237d94-bc0e-40ea-895c-d444c59f812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosticsImage-originalMean</th>\n",
       "      <th>diagnosticsImage-originalMinimum</th>\n",
       "      <th>diagnosticsMask-originalVoxelNum</th>\n",
       "      <th>originalshapeFlatness</th>\n",
       "      <th>originalshapeLeastAxisLength</th>\n",
       "      <th>originalshapeMaximum2DDiameterRow</th>\n",
       "      <th>originalshapeMaximum2DDiameterSlice</th>\n",
       "      <th>originalshapeMeshVolume</th>\n",
       "      <th>originalshapeMinorAxisLength</th>\n",
       "      <th>originalshapeSphericity</th>\n",
       "      <th>...</th>\n",
       "      <th>wavelet-LLLglszmGrayLevelNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmLowGrayLevelZoneEmphasis</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformityNormalized</th>\n",
       "      <th>wavelet-LLLglszmSmallAreaEmphasis</th>\n",
       "      <th>wavelet-LLLglszmZoneEntropy</th>\n",
       "      <th>wavelet-LLLglszmZonePercentage</th>\n",
       "      <th>wavelet-LLLngtdmCoarseness</th>\n",
       "      <th>wavelet-LLLngtdmContrast</th>\n",
       "      <th>wavelet-LLLngtdmStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L35</th>\n",
       "      <td>-590.996050</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>0.567642</td>\n",
       "      <td>17.480034</td>\n",
       "      <td>31.824932</td>\n",
       "      <td>34.239088</td>\n",
       "      <td>7708.781387</td>\n",
       "      <td>22.177547</td>\n",
       "      <td>0.709051</td>\n",
       "      <td>...</td>\n",
       "      <td>27.328657</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>158.450902</td>\n",
       "      <td>0.317537</td>\n",
       "      <td>0.580434</td>\n",
       "      <td>6.494470</td>\n",
       "      <td>0.264721</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.112960</td>\n",
       "      <td>2.505126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L44</th>\n",
       "      <td>-664.262732</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>0.440898</td>\n",
       "      <td>14.373141</td>\n",
       "      <td>34.276051</td>\n",
       "      <td>32.240447</td>\n",
       "      <td>8627.979492</td>\n",
       "      <td>27.127836</td>\n",
       "      <td>0.697033</td>\n",
       "      <td>...</td>\n",
       "      <td>32.483412</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>112.620853</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.524739</td>\n",
       "      <td>6.171855</td>\n",
       "      <td>0.221174</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.559084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X65</th>\n",
       "      <td>-678.863086</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>12095.0</td>\n",
       "      <td>0.521147</td>\n",
       "      <td>32.076241</td>\n",
       "      <td>71.424541</td>\n",
       "      <td>70.037744</td>\n",
       "      <td>57577.086360</td>\n",
       "      <td>43.490283</td>\n",
       "      <td>0.655156</td>\n",
       "      <td>...</td>\n",
       "      <td>132.707956</td>\n",
       "      <td>0.012702</td>\n",
       "      <td>236.119839</td>\n",
       "      <td>0.237784</td>\n",
       "      <td>0.489621</td>\n",
       "      <td>5.948185</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.109557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X58</th>\n",
       "      <td>-648.246681</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.685351</td>\n",
       "      <td>9.026083</td>\n",
       "      <td>24.103604</td>\n",
       "      <td>11.623848</td>\n",
       "      <td>729.836266</td>\n",
       "      <td>9.988381</td>\n",
       "      <td>0.695744</td>\n",
       "      <td>...</td>\n",
       "      <td>4.710145</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>25.231884</td>\n",
       "      <td>0.365679</td>\n",
       "      <td>0.613855</td>\n",
       "      <td>5.181363</td>\n",
       "      <td>0.392045</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>1.034368</td>\n",
       "      <td>9.291845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>-600.984933</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.614269</td>\n",
       "      <td>7.908654</td>\n",
       "      <td>17.802055</td>\n",
       "      <td>12.827708</td>\n",
       "      <td>839.388805</td>\n",
       "      <td>11.355911</td>\n",
       "      <td>0.753804</td>\n",
       "      <td>...</td>\n",
       "      <td>7.411765</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>57.250000</td>\n",
       "      <td>0.420956</td>\n",
       "      <td>0.673088</td>\n",
       "      <td>5.633501</td>\n",
       "      <td>0.521073</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>11.364464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X34</th>\n",
       "      <td>-638.027673</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>17.108227</td>\n",
       "      <td>35.733521</td>\n",
       "      <td>28.381363</td>\n",
       "      <td>8521.587433</td>\n",
       "      <td>21.537387</td>\n",
       "      <td>0.650659</td>\n",
       "      <td>...</td>\n",
       "      <td>59.316891</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>208.608371</td>\n",
       "      <td>0.311821</td>\n",
       "      <td>0.573856</td>\n",
       "      <td>5.860988</td>\n",
       "      <td>0.295756</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.740093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L52</th>\n",
       "      <td>-620.813483</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>5249.0</td>\n",
       "      <td>0.573858</td>\n",
       "      <td>23.268326</td>\n",
       "      <td>41.748175</td>\n",
       "      <td>48.856055</td>\n",
       "      <td>19690.859380</td>\n",
       "      <td>30.373199</td>\n",
       "      <td>0.720158</td>\n",
       "      <td>...</td>\n",
       "      <td>114.811057</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>480.682295</td>\n",
       "      <td>0.336377</td>\n",
       "      <td>0.600516</td>\n",
       "      <td>5.992634</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>0.198260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>-539.902547</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.270528</td>\n",
       "      <td>8.809353</td>\n",
       "      <td>25.858086</td>\n",
       "      <td>14.502828</td>\n",
       "      <td>1664.852865</td>\n",
       "      <td>10.103964</td>\n",
       "      <td>0.616014</td>\n",
       "      <td>...</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>88.804444</td>\n",
       "      <td>0.394686</td>\n",
       "      <td>0.650065</td>\n",
       "      <td>6.211085</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.935525</td>\n",
       "      <td>6.807361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L41</th>\n",
       "      <td>-578.514587</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.410397</td>\n",
       "      <td>6.165698</td>\n",
       "      <td>17.414523</td>\n",
       "      <td>11.275838</td>\n",
       "      <td>598.382812</td>\n",
       "      <td>9.522956</td>\n",
       "      <td>0.738027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>15.192308</td>\n",
       "      <td>0.292160</td>\n",
       "      <td>0.555985</td>\n",
       "      <td>5.195350</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.035838</td>\n",
       "      <td>0.250684</td>\n",
       "      <td>4.360344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>-639.387528</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000868</td>\n",
       "      <td>5.669270</td>\n",
       "      <td>96.106771</td>\n",
       "      <td>3.279435</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.078011</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.863426</td>\n",
       "      <td>3.740602</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.243869</td>\n",
       "      <td>0.212977</td>\n",
       "      <td>14.239747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosticsImage-originalMean  diagnosticsImage-originalMinimum  \\\n",
       "L35                    -590.996050                           -1024.0   \n",
       "L44                    -664.262732                           -1024.0   \n",
       "X65                    -678.863086                           -1024.0   \n",
       "X58                    -648.246681                           -1024.0   \n",
       "x20                    -600.984933                           -1024.0   \n",
       "..                             ...                               ...   \n",
       "X34                    -638.027673                           -1024.0   \n",
       "L52                    -620.813483                           -1024.0   \n",
       "X15                    -539.902547                           -1024.0   \n",
       "L41                    -578.514587                           -1024.0   \n",
       "L2                     -639.387528                           -1024.0   \n",
       "\n",
       "     diagnosticsMask-originalVoxelNum  originalshapeFlatness  \\\n",
       "L35                            1885.0               0.567642   \n",
       "L44                            1908.0               0.440898   \n",
       "X65                           12095.0               0.521147   \n",
       "X58                             176.0               0.685351   \n",
       "x20                             261.0               0.614269   \n",
       "..                                ...                    ...   \n",
       "X34                            2262.0               0.428130   \n",
       "L52                            5249.0               0.573858   \n",
       "X15                             459.0               0.270528   \n",
       "L41                             168.0               0.410397   \n",
       "L2                               30.0               0.000000   \n",
       "\n",
       "     originalshapeLeastAxisLength  originalshapeMaximum2DDiameterRow  \\\n",
       "L35                     17.480034                          31.824932   \n",
       "L44                     14.373141                          34.276051   \n",
       "X65                     32.076241                          71.424541   \n",
       "X58                      9.026083                          24.103604   \n",
       "x20                      7.908654                          17.802055   \n",
       "..                            ...                                ...   \n",
       "X34                     17.108227                          35.733521   \n",
       "L52                     23.268326                          41.748175   \n",
       "X15                      8.809353                          25.858086   \n",
       "L41                      6.165698                          17.414523   \n",
       "L2                       0.000000                           9.000868   \n",
       "\n",
       "     originalshapeMaximum2DDiameterSlice  originalshapeMeshVolume  \\\n",
       "L35                            34.239088              7708.781387   \n",
       "L44                            32.240447              8627.979492   \n",
       "X65                            70.037744             57577.086360   \n",
       "X58                            11.623848               729.836266   \n",
       "x20                            12.827708               839.388805   \n",
       "..                                   ...                      ...   \n",
       "X34                            28.381363              8521.587433   \n",
       "L52                            48.856055             19690.859380   \n",
       "X15                            14.502828              1664.852865   \n",
       "L41                            11.275838               598.382812   \n",
       "L2                              5.669270                96.106771   \n",
       "\n",
       "     originalshapeMinorAxisLength  originalshapeSphericity  ...  \\\n",
       "L35                     22.177547                 0.709051  ...   \n",
       "L44                     27.127836                 0.697033  ...   \n",
       "X65                     43.490283                 0.655156  ...   \n",
       "X58                      9.988381                 0.695744  ...   \n",
       "x20                     11.355911                 0.753804  ...   \n",
       "..                            ...                      ...  ...   \n",
       "X34                     21.537387                 0.650659  ...   \n",
       "L52                     30.373199                 0.720158  ...   \n",
       "X15                     10.103964                 0.616014  ...   \n",
       "L41                      9.522956                 0.738027  ...   \n",
       "L2                       3.279435                 0.772361  ...   \n",
       "\n",
       "     wavelet-LLLglszmGrayLevelNonUniformity  \\\n",
       "L35                               27.328657   \n",
       "L44                               32.483412   \n",
       "X65                              132.707956   \n",
       "X58                                4.710145   \n",
       "x20                                7.411765   \n",
       "..                                      ...   \n",
       "X34                               59.316891   \n",
       "L52                              114.811057   \n",
       "X15                                8.760000   \n",
       "L41                                3.461538   \n",
       "L2                                 2.250000   \n",
       "\n",
       "     wavelet-LLLglszmLowGrayLevelZoneEmphasis  \\\n",
       "L35                                  0.005205   \n",
       "L44                                  0.018894   \n",
       "X65                                  0.012702   \n",
       "X58                                  0.031861   \n",
       "x20                                  0.010612   \n",
       "..                                        ...   \n",
       "X34                                  0.012227   \n",
       "L52                                  0.009208   \n",
       "X15                                  0.013163   \n",
       "L41                                  0.026416   \n",
       "L2                                   0.078011   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformity  \\\n",
       "L35                             158.450902   \n",
       "L44                             112.620853   \n",
       "X65                             236.119839   \n",
       "X58                              25.231884   \n",
       "x20                              57.250000   \n",
       "..                                     ...   \n",
       "X34                             208.608371   \n",
       "L52                             480.682295   \n",
       "X15                              88.804444   \n",
       "L41                              15.192308   \n",
       "L2                               17.000000   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformityNormalized  \\\n",
       "L35                                         0.317537   \n",
       "L44                                         0.266874   \n",
       "X65                                         0.237784   \n",
       "X58                                         0.365679   \n",
       "x20                                         0.420956   \n",
       "..                                               ...   \n",
       "X34                                         0.311821   \n",
       "L52                                         0.336377   \n",
       "X15                                         0.394686   \n",
       "L41                                         0.292160   \n",
       "L2                                          0.708333   \n",
       "\n",
       "     wavelet-LLLglszmSmallAreaEmphasis  wavelet-LLLglszmZoneEntropy  \\\n",
       "L35                           0.580434                     6.494470   \n",
       "L44                           0.524739                     6.171855   \n",
       "X65                           0.489621                     5.948185   \n",
       "X58                           0.613855                     5.181363   \n",
       "x20                           0.673088                     5.633501   \n",
       "..                                 ...                          ...   \n",
       "X34                           0.573856                     5.860988   \n",
       "L52                           0.600516                     5.992634   \n",
       "X15                           0.650065                     6.211085   \n",
       "L41                           0.555985                     5.195350   \n",
       "L2                            0.863426                     3.740602   \n",
       "\n",
       "     wavelet-LLLglszmZonePercentage  wavelet-LLLngtdmCoarseness  \\\n",
       "L35                        0.264721                    0.003280   \n",
       "L44                        0.221174                    0.004015   \n",
       "X65                        0.082100                    0.000596   \n",
       "X58                        0.392045                    0.013722   \n",
       "x20                        0.521073                    0.033755   \n",
       "..                              ...                         ...   \n",
       "X34                        0.295756                    0.003178   \n",
       "L52                        0.272242                    0.001339   \n",
       "X15                        0.490196                    0.007549   \n",
       "L41                        0.309524                    0.035838   \n",
       "L2                         0.800000                    0.243869   \n",
       "\n",
       "     wavelet-LLLngtdmContrast  wavelet-LLLngtdmStrength  \n",
       "L35                  0.112960                  2.505126  \n",
       "L44                  0.066445                  0.559084  \n",
       "X65                  0.014271                  0.109557  \n",
       "X58                  1.034368                  9.291845  \n",
       "x20                  0.192491                 11.364464  \n",
       "..                        ...                       ...  \n",
       "X34                  0.039251                  0.740093  \n",
       "L52                  0.059543                  0.198260  \n",
       "X15                  0.935525                  6.807361  \n",
       "L41                  0.250684                  4.360344  \n",
       "L2                   0.212977                 14.239747  \n",
       "\n",
       "[138 rows x 459 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data.iloc[:, 0]\n",
    "features = data.iloc[:,1:]\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90f3976-1b9b-470c-96d6-c6b93589aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34896209,  0.36214298,  0.04052877, ..., -0.49155479,\n",
       "        -0.28699748, -0.41124507],\n",
       "       [-0.14606636,  0.36214298,  0.04942554, ..., -0.48101849,\n",
       "        -0.38064232, -0.53070188],\n",
       "       [-0.24471408,  0.36214298,  3.98991884, ..., -0.53000591,\n",
       "        -0.48567859, -0.55829591],\n",
       "       ...,\n",
       "       [ 0.69417683,  0.36214298, -0.51107066, ..., -0.43039906,\n",
       "         1.36897842, -0.14715453],\n",
       "       [ 0.43329345,  0.36214298, -0.62363408, ..., -0.02507899,\n",
       "        -0.00973321, -0.29736347],\n",
       "       [ 0.02200367,  0.36214298, -0.67701467, ...,  2.95547114,\n",
       "        -0.08564538,  0.30907875]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer = StandardScaler()\n",
    "features_SS = transfer.fit_transform(features)\n",
    "\n",
    "features_SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7c3c17-ffd4-458d-b3ed-412e22f5937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alphas_ = np.logspace(-2,0,300)\n",
    "\n",
    "\n",
    "# lassocv = LassoCV(alphas = alphas_,cv = 10,max_iter = 100000).fit(features_SS,target)\n",
    "# lassocv.alpha_\n",
    "\n",
    "# features = data[features.columns[lassocv.coef_!=0]]\n",
    "# print(len(features.columns))\n",
    "\n",
    "\n",
    "# features_SS =features_SS[:, pd.DataFrame(features_SS).columns[lassocv.coef_!=0]]\n",
    "# features_SS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92da3c6-15a3-4cfd-a990-a35f784d54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ae857f-7d05-435c-bb5d-ff2e7b44904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lda = lda.fit_transform(features_SS,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd540e6a-9ec6-4241-b938-6cf53badd09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3074c99e-1eb0-4b6e-bf79-fa46f8840ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features_lda, target, \n",
    "    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f69f07-e240-4cd6-b6b4-7d78f62888af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea263245-3d75-4207-b6f2-8c7ed1c9145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29da1a3b-2f82-4acb-8e4b-f9f439c850fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#邏輯回歸\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "\n",
    "log.fit(train_features, train_target)\n",
    "test_predict = log.predict(test_features)\n",
    "# print(test_target)\n",
    "# print(test_predict)\n",
    "log.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be60bbb-ab27-4c1e-900d-f0f130410a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8261d8-c0c0-4520-803d-3fe11b3a5ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba434ccb-b5f4-43ee-bd3b-88b1126c82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5523d0-4694-468c-bdcb-2a02872666e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d5d5cf-8c90-447e-ba68-b7826f9d04f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = tree_clf.predict(test_features)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1ffa795-f5e3-4fa5-acc4-899924ef7513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4a0343-c7fb-4d48-8678-e9bb53416f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "plot_tree(tree_clf) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210a33e-b2a6-4fd9-8a77-049a8008359e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75336cda-21c3-43a3-8026-09656ffd57f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04027591-e702-403c-b89d-e204567e27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "#randomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 20).fit(train_features,train_target)\n",
    "score_rf = model_rf.score(test_features,test_target)\n",
    "print(score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31050c9a-0e24-4c32-83c4-55af3bd64ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4a943-f9ef-4036-87b2-0b4be7ed641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c22ae7-dbe5-4363-b612-fddb15ebc216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1)\n",
    "svc_linear.fit(train_features, train_target)\n",
    "test_predict = svc_linear.predict(test_features)\n",
    "svc_linear.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e29035d-4ab6-4bad-ab91-d95070ebd363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_linear.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168cfb3-e28c-48ef-b664-a61479d83afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6061b-5fa8-4de4-b8e6-a957429843c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "337c82d5-6e1b-40c5-9a4c-c2e6475bca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0)\n",
    "svc_rbf.fit(train_features, train_target)\n",
    "test_predict = svc_rbf.predict(test_features)\n",
    "svc_rbf.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22009fa8-dd75-48c4-894f-240c03ec7c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fd174-ca32-4247-a109-6677522a4b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104b43a-386c-4aa9-90b0-a7842eed424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a939507-f567-4f81-8f1d-46d6722d09a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809523809523809"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0)\n",
    "svc_poly.fit(train_features, train_target)\n",
    "test_predict = svc_poly.predict(test_features)\n",
    "svc_poly.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85372590-3bd5-4b00-ace8-a3c7e49bc4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27842b5-09e0-4e72-a350-317799fd3ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd1216-5b4f-4bb1-bb6d-12848e503869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa290bb2-bb4d-48bd-8740-95e3f13c7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9523809523809523\n",
      "SVC 0.9523809523809523\n",
      "SVC 0.8809523809523809\n",
      "SVC 0.9523809523809523\n",
      "VotingClassifier 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#集成算法\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='hard')\n",
    "#, ('tree', tree_clf)\n",
    "voting_clf.fit(train_features, train_target)\n",
    "\n",
    "for clf in (log_clf, svc_linear,svc_poly,svc_rbf, voting_clf):\n",
    "    clf.fit(train_features, train_target)\n",
    "    print(clf.__class__.__name__, clf.score(test_features, test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7b1baa4-7abd-4074-a708-928528417710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762afe1b-db48-4293-93bf-117d50fdcc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f72f4-d3ef-4de0-a01b-8e6fbc937ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4454a2-a600-4f9f-8f4e-34ea669cd7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9523809523809523\n",
      "SVC 0.9523809523809523\n",
      "SVC 0.8809523809523809\n",
      "SVC 0.9523809523809523\n",
      "VotingClassifier 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "     estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='soft')\n",
    "#, ('tree', tree_clf)\n",
    "voting_clf.fit(train_features, train_target)\n",
    "for clf in (log_clf,  svc_linear,svc_poly,svc_rbf, voting_clf):\n",
    "    clf.fit(train_features, train_target)\n",
    "    print(clf.__class__.__name__, clf.score(test_features, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cdc6cd6-76bb-4b13-84a5-feaaf3e52e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90446fa0-a7ef-4841-8694-62eb8ed70929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81e882c3-59d8-4f82-a840-d5f02a49ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "log_ensemble = LogisticRegression()\n",
    "\n",
    "stk_clf = StackingClassifier(\n",
    "      estimators=[('lr', log_clf), ('svc_l', svc_linear),\n",
    "                  ('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    final_estimator=log_ensemble)\n",
    "\n",
    "stk_clf.fit(train_features, train_target)\n",
    "\n",
    "stk_clf.score(test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce991f-bb9d-4b43-a754-80ec9cf3c431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86dd71-b00c-4a8c-9a81-3e64400a5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffb0a4-1fce-4a6c-80a0-c0afeb76580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c693954-c9b6-4d91-9662-12e0c6736134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941098901098901\n"
     ]
    }
   ],
   "source": [
    "rkf=RepeatedKFold(n_splits=10,n_repeats=10)\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "     estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='soft')\n",
    "sum_score = 0\n",
    "\n",
    "for train_index, test_index in rkf.split(features_lda):\n",
    "    X_train =pd.DataFrame(features_lda).iloc[train_index]\n",
    "    X_test =pd.DataFrame(features_lda).iloc[test_index]\n",
    "    # print(train_index)\n",
    "    # print(test_index)\n",
    "    y_train =pd.DataFrame(target).iloc[train_index]\n",
    "    y_test =pd.DataFrame(target).iloc[test_index]\n",
    "    model_svm = voting_clf.fit(X_train,y_train)\n",
    "    score_svm=model_svm.score(X_test,y_test)\n",
    "    sum_score+=score_svm\n",
    "    \n",
    "print(sum_score/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae7579-bc36-4a34-964c-2ef0f88e83ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b1766-f2cf-43ca-91d6-0ab5b7d1ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5286f-40c1-419d-8903-38b65fb728de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf8ab5-b196-4370-acd4-e8a7701c911d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dae01-dae0-4658-ab99-95d6527b70d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67969741-8382-4a0c-8b3b-344677f27fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cfba5a6-a600-4fda-947b-9b7cc5efc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80890-a6e7-4991-9439-b03f2c071075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cacf574-8e1c-4bd8-80f1-686dc3ef102a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e07382d-aabd-43d4-b5f8-6123541097dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_95 = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3bd6285-a442-43e6-822f-43e5825dfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_95 = pca_95.fit_transform(features_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d66561e-5617-4bdc-98dc-e7701f255545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.96052821e+00,  3.05694449e+00, -4.35750354e+00, ...,\n",
       "         1.88624210e-01, -6.82126992e-02, -1.91647078e-01],\n",
       "       [-1.23542558e-01,  7.80539892e+00, -3.04354832e+00, ...,\n",
       "        -9.16013834e-02, -2.23078856e-01,  2.71408390e-01],\n",
       "       [-6.95256545e+00,  1.69306301e+01,  1.37496326e+01, ...,\n",
       "        -6.96866222e-02,  7.54600458e-02, -1.08602347e-01],\n",
       "       ...,\n",
       "       [ 1.94955821e+00, -1.36782202e+00, -7.12628708e+00, ...,\n",
       "         3.04589913e-01, -3.91253775e-02,  9.54571788e-02],\n",
       "       [ 9.59533193e+00,  2.05924781e+00, -4.41190210e+00, ...,\n",
       "         4.46495127e-02, -2.21484695e-01,  3.04050461e-01],\n",
       "       [ 1.78973560e+01, -6.34777898e+00,  2.84825673e+00, ...,\n",
       "         4.01255368e-03,  1.43630046e-02, -2.00730822e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c2bc5-5fb2-41a9-ba19-2de82366cea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28776ea0-6569-410e-a5cc-bc9dc87b9054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac620775-cc78-4ff6-a03c-f2f931185a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a635b32-6afe-4256-9e4f-5e3bd5e56b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 100)\n",
      "(117,)\n",
      "(21, 100)\n",
      "(21,)\n",
      "(99, 100)\n",
      "(99,)\n",
      "(18, 100)\n",
      "(18,)\n",
      "(21, 100)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "train_features_full, test_features, train_target_full, test_target = train_test_split(\n",
    "    features_95, target, \n",
    "    test_size = 0.15)\n",
    "print(train_features_full.shape)\n",
    "print(train_target_full.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)\n",
    "train_features, validation_features, train_target, validation_target = train_test_split(\n",
    "    train_features_full, train_target_full, \n",
    "    test_size = 0.15)\n",
    "print(train_features.shape)\n",
    "print(train_target.shape)\n",
    "print(validation_features.shape)\n",
    "print(validation_target.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed0733f1-deac-43b8-9214-57b66daced09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 19:54:11.011090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:54:12.492126: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "input_  = keras.layers.Input(shape = train_features.shape[1:])\n",
    "hidden1 = keras.layers.Dense(10,activation='selu')(input_)\n",
    "hidden2 = keras.layers.Dense(5,activation='selu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1,activation='sigmoid')(concat)\n",
    "model_wide = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9fcb61e-9927-40fe-8f61-e5d602adfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "020cebab-5868-4a3a-ada8-5e0acbd427e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 59ms/step - loss: 1.1474 - accuracy: 0.4848 - val_loss: 0.6619 - val_accuracy: 0.7222\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0614 - accuracy: 0.4848 - val_loss: 0.6500 - val_accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0031 - accuracy: 0.5051 - val_loss: 0.6375 - val_accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9576 - accuracy: 0.4848 - val_loss: 0.6256 - val_accuracy: 0.7222\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9176 - accuracy: 0.5051 - val_loss: 0.6151 - val_accuracy: 0.7222\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8801 - accuracy: 0.5152 - val_loss: 0.6040 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8445 - accuracy: 0.5354 - val_loss: 0.5933 - val_accuracy: 0.7222\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8116 - accuracy: 0.5758 - val_loss: 0.5835 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7793 - accuracy: 0.5758 - val_loss: 0.5746 - val_accuracy: 0.7222\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7510 - accuracy: 0.6061 - val_loss: 0.5671 - val_accuracy: 0.7222\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7210 - accuracy: 0.6263 - val_loss: 0.5589 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6944 - accuracy: 0.6364 - val_loss: 0.5511 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.6465 - val_loss: 0.5433 - val_accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.5370 - val_accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6155 - accuracy: 0.6667 - val_loss: 0.5316 - val_accuracy: 0.6667\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5915 - accuracy: 0.6970 - val_loss: 0.5281 - val_accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5683 - accuracy: 0.6970 - val_loss: 0.5244 - val_accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5496 - accuracy: 0.7374 - val_loss: 0.5222 - val_accuracy: 0.7222\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5294 - accuracy: 0.7273 - val_loss: 0.5202 - val_accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.7374 - val_loss: 0.5204 - val_accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4915 - accuracy: 0.7677 - val_loss: 0.5208 - val_accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4779 - accuracy: 0.7677 - val_loss: 0.5220 - val_accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4619 - accuracy: 0.7677 - val_loss: 0.5238 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5251 - val_accuracy: 0.7222\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.8081 - val_loss: 0.5283 - val_accuracy: 0.7222\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4220 - accuracy: 0.8182 - val_loss: 0.5327 - val_accuracy: 0.7778\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8182 - val_loss: 0.5366 - val_accuracy: 0.7778\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8283 - val_loss: 0.5400 - val_accuracy: 0.7778\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8384 - val_loss: 0.5444 - val_accuracy: 0.7778\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.8485 - val_loss: 0.5477 - val_accuracy: 0.7778\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3666 - accuracy: 0.8384 - val_loss: 0.5533 - val_accuracy: 0.7778\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3563 - accuracy: 0.8687 - val_loss: 0.5579 - val_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3479 - accuracy: 0.8788 - val_loss: 0.5634 - val_accuracy: 0.7222\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.8687 - val_loss: 0.5682 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.8889 - val_loss: 0.5694 - val_accuracy: 0.7222\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.8889 - val_loss: 0.5742 - val_accuracy: 0.7222\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3134 - accuracy: 0.8788 - val_loss: 0.5762 - val_accuracy: 0.7222\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3071 - accuracy: 0.8788 - val_loss: 0.5808 - val_accuracy: 0.7222\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2980 - accuracy: 0.8889 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.8788 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2827 - accuracy: 0.8990 - val_loss: 0.5974 - val_accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2798 - accuracy: 0.9091 - val_loss: 0.6017 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2720 - accuracy: 0.9091 - val_loss: 0.6048 - val_accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2633 - accuracy: 0.9192 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2571 - accuracy: 0.9192 - val_loss: 0.6163 - val_accuracy: 0.6667\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.6219 - val_accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2462 - accuracy: 0.9192 - val_loss: 0.6252 - val_accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2393 - accuracy: 0.9192 - val_loss: 0.6339 - val_accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2336 - accuracy: 0.9192 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2266 - accuracy: 0.9293 - val_loss: 0.6439 - val_accuracy: 0.6111\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2223 - accuracy: 0.9293 - val_loss: 0.6500 - val_accuracy: 0.6111\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2166 - accuracy: 0.9293 - val_loss: 0.6557 - val_accuracy: 0.6111\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2099 - accuracy: 0.9394 - val_loss: 0.6623 - val_accuracy: 0.6111\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2041 - accuracy: 0.9495 - val_loss: 0.6707 - val_accuracy: 0.6111\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1982 - accuracy: 0.9495 - val_loss: 0.6763 - val_accuracy: 0.6111\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1950 - accuracy: 0.9596 - val_loss: 0.6845 - val_accuracy: 0.6111\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1890 - accuracy: 0.9697 - val_loss: 0.6902 - val_accuracy: 0.6111\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1830 - accuracy: 0.9798 - val_loss: 0.6966 - val_accuracy: 0.6111\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1778 - accuracy: 0.9798 - val_loss: 0.7068 - val_accuracy: 0.6111\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1726 - accuracy: 0.9697 - val_loss: 0.7108 - val_accuracy: 0.6111\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1693 - accuracy: 0.9798 - val_loss: 0.7193 - val_accuracy: 0.6111\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1645 - accuracy: 0.9798 - val_loss: 0.7282 - val_accuracy: 0.6111\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1583 - accuracy: 0.9899 - val_loss: 0.7342 - val_accuracy: 0.6111\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9899 - val_loss: 0.7435 - val_accuracy: 0.6111\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1494 - accuracy: 0.9899 - val_loss: 0.7520 - val_accuracy: 0.6111\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.9899 - val_loss: 0.7572 - val_accuracy: 0.6111\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1402 - accuracy: 0.9899 - val_loss: 0.7687 - val_accuracy: 0.6111\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.9899 - val_loss: 0.7750 - val_accuracy: 0.6111\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1310 - accuracy: 0.9899 - val_loss: 0.7882 - val_accuracy: 0.6111\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 0.9899 - val_loss: 0.7929 - val_accuracy: 0.6111\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1234 - accuracy: 0.9899 - val_loss: 0.7999 - val_accuracy: 0.6111\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9899 - val_loss: 0.8092 - val_accuracy: 0.6111\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1151 - accuracy: 0.9899 - val_loss: 0.8220 - val_accuracy: 0.6111\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1108 - accuracy: 0.9899 - val_loss: 0.8315 - val_accuracy: 0.6111\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1091 - accuracy: 0.9899 - val_loss: 0.8376 - val_accuracy: 0.6111\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1048 - accuracy: 0.9899 - val_loss: 0.8502 - val_accuracy: 0.6111\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1006 - accuracy: 0.9899 - val_loss: 0.8572 - val_accuracy: 0.6111\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0972 - accuracy: 0.9899 - val_loss: 0.8632 - val_accuracy: 0.6111\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0943 - accuracy: 0.9899 - val_loss: 0.8745 - val_accuracy: 0.6111\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9899 - val_loss: 0.8861 - val_accuracy: 0.6111\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0877 - accuracy: 0.9899 - val_loss: 0.8989 - val_accuracy: 0.6111\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.6111\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.6111\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.6111\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9899 - val_loss: 0.9494 - val_accuracy: 0.6111\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.6111\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.6111\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.6111\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.6111\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.6111\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.0319 - val_accuracy: 0.6111\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 1.0520 - val_accuracy: 0.6111\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 1.0664 - val_accuracy: 0.6111\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 1.0827 - val_accuracy: 0.6111\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.6111\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.6111\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.6111\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 1.1447 - val_accuracy: 0.6111\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.6111\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.1792 - val_accuracy: 0.6111\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.6111\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.6111\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.2249 - val_accuracy: 0.6111\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.6111\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.6111\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.6111\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.2926 - val_accuracy: 0.6111\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.6111\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.3361 - val_accuracy: 0.6111\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.3580 - val_accuracy: 0.6111\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.3710 - val_accuracy: 0.6111\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.3886 - val_accuracy: 0.6111\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.4027 - val_accuracy: 0.6111\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.4244 - val_accuracy: 0.6111\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.4510 - val_accuracy: 0.6111\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.4660 - val_accuracy: 0.6111\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.4852 - val_accuracy: 0.6111\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5032 - val_accuracy: 0.6111\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5240 - val_accuracy: 0.6111\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5425 - val_accuracy: 0.6111\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.5616 - val_accuracy: 0.6111\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.6111\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6026 - val_accuracy: 0.6111\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6204 - val_accuracy: 0.6111\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.6430 - val_accuracy: 0.6111\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.6111\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.6793 - val_accuracy: 0.6111\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.6111\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.6111\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.6111\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7609 - val_accuracy: 0.6111\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.6111\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.6111\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8236 - val_accuracy: 0.6111\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.6111\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.6111\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8823 - val_accuracy: 0.6111\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9086 - val_accuracy: 0.6111\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.6111\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9526 - val_accuracy: 0.6111\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9727 - val_accuracy: 0.6111\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9954 - val_accuracy: 0.6111\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0111 - val_accuracy: 0.6111\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0297 - val_accuracy: 0.6111\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.6111\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.6111\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0910 - val_accuracy: 0.6111\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1134 - val_accuracy: 0.6111\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1319 - val_accuracy: 0.6111\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.6111\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1692 - val_accuracy: 0.6111\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1845 - val_accuracy: 0.6111\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.7489e-04 - accuracy: 1.0000 - val_loss: 2.2082 - val_accuracy: 0.6111\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.0034e-04 - accuracy: 1.0000 - val_loss: 2.2247 - val_accuracy: 0.6111\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 8.5823e-04 - accuracy: 1.0000 - val_loss: 2.2454 - val_accuracy: 0.6111\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.9051e-04 - accuracy: 1.0000 - val_loss: 2.2642 - val_accuracy: 0.6111\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.2773e-04 - accuracy: 1.0000 - val_loss: 2.2812 - val_accuracy: 0.6111\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.8011e-04 - accuracy: 1.0000 - val_loss: 2.2960 - val_accuracy: 0.6111\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3663e-04 - accuracy: 1.0000 - val_loss: 2.3222 - val_accuracy: 0.6111\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9234e-04 - accuracy: 1.0000 - val_loss: 2.3424 - val_accuracy: 0.6111\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.4869e-04 - accuracy: 1.0000 - val_loss: 2.3600 - val_accuracy: 0.6111\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1877e-04 - accuracy: 1.0000 - val_loss: 2.3795 - val_accuracy: 0.6111\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9451e-04 - accuracy: 1.0000 - val_loss: 2.3971 - val_accuracy: 0.6111\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5049e-04 - accuracy: 1.0000 - val_loss: 2.4211 - val_accuracy: 0.6111\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2939e-04 - accuracy: 1.0000 - val_loss: 2.4379 - val_accuracy: 0.6111\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.9742e-04 - accuracy: 1.0000 - val_loss: 2.4506 - val_accuracy: 0.6111\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7064e-04 - accuracy: 1.0000 - val_loss: 2.4669 - val_accuracy: 0.6111\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5392e-04 - accuracy: 1.0000 - val_loss: 2.4807 - val_accuracy: 0.6111\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.2625e-04 - accuracy: 1.0000 - val_loss: 2.5026 - val_accuracy: 0.6111\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1495e-04 - accuracy: 1.0000 - val_loss: 2.5184 - val_accuracy: 0.6111\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.9873e-04 - accuracy: 1.0000 - val_loss: 2.5446 - val_accuracy: 0.6111\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7917e-04 - accuracy: 1.0000 - val_loss: 2.5566 - val_accuracy: 0.6111\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.6606e-04 - accuracy: 1.0000 - val_loss: 2.5685 - val_accuracy: 0.6111\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4759e-04 - accuracy: 1.0000 - val_loss: 2.5885 - val_accuracy: 0.6111\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3313e-04 - accuracy: 1.0000 - val_loss: 2.6063 - val_accuracy: 0.6111\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2038e-04 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 0.6111\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: 2.6387 - val_accuracy: 0.6111\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9679e-04 - accuracy: 1.0000 - val_loss: 2.6510 - val_accuracy: 0.6111\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.8796e-04 - accuracy: 1.0000 - val_loss: 2.6700 - val_accuracy: 0.6111\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.8059e-04 - accuracy: 1.0000 - val_loss: 2.6889 - val_accuracy: 0.6111\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7257e-04 - accuracy: 1.0000 - val_loss: 2.7008 - val_accuracy: 0.6111\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6335e-04 - accuracy: 1.0000 - val_loss: 2.7153 - val_accuracy: 0.6111\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5515e-04 - accuracy: 1.0000 - val_loss: 2.7295 - val_accuracy: 0.6111\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5087e-04 - accuracy: 1.0000 - val_loss: 2.7441 - val_accuracy: 0.6111\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4208e-04 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.6111\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3465e-04 - accuracy: 1.0000 - val_loss: 2.7718 - val_accuracy: 0.6111\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3114e-04 - accuracy: 1.0000 - val_loss: 2.7833 - val_accuracy: 0.6111\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2366e-04 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.6111\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1855e-04 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.6111\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1431e-04 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.6111\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1010e-04 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.6111\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: 2.8460 - val_accuracy: 0.6111\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0371e-04 - accuracy: 1.0000 - val_loss: 2.8590 - val_accuracy: 0.6111\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8978e-05 - accuracy: 1.0000 - val_loss: 2.8693 - val_accuracy: 0.6111\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.3756e-05 - accuracy: 1.0000 - val_loss: 2.8798 - val_accuracy: 0.6111\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0845e-05 - accuracy: 1.0000 - val_loss: 2.8916 - val_accuracy: 0.6111\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8595e-05 - accuracy: 1.0000 - val_loss: 2.9016 - val_accuracy: 0.6111\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4486e-05 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.6111\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2285e-05 - accuracy: 1.0000 - val_loss: 2.9244 - val_accuracy: 0.6111\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0530e-05 - accuracy: 1.0000 - val_loss: 2.9347 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1ee774210>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wide.fit(train_features, train_target, batch_size = 20, epochs=200,\n",
    "         validation_data=(validation_features, validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b816f19f-dc90-4b68-9dca-1070144a17e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_len = features_95.shape[1]\n",
    "\n",
    "features_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a64eedf-11b9-4b52-aed1-c5ec9f0c8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0324705 ,  1.03812917, -0.70540356, ..., -0.02453346,\n",
       "        -0.09005355,  0.0477107 ],\n",
       "       [ 0.75009176, -0.03033937,  1.12703644, ..., -0.03323855,\n",
       "        -0.0731497 ,  0.06842111],\n",
       "       [-2.19057252, -2.00012529,  0.94514321, ..., -0.04245039,\n",
       "         0.03385121, -0.09882948],\n",
       "       ...,\n",
       "       [ 0.80940527,  2.46746937, -1.04181268, ..., -0.04748264,\n",
       "         0.01807904,  0.02439666],\n",
       "       [ 0.11454447, -1.70930156, -0.51640029, ..., -0.07204704,\n",
       "         0.11502177, -0.15272775],\n",
       "       [ 0.51597735, -0.70315113, -1.49639638, ...,  0.18136047,\n",
       "         0.20662214, -0.0793023 ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_A = train_features[:,:features_len//3]\n",
    "train_features_B = train_features[:,features_len//3:]\n",
    "\n",
    "validation_features_A = validation_features[:,:features_len//3]\n",
    "validation_features_B = validation_features[:,features_len//3:]\n",
    "train_features_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4a1a15b-a300-46b1-9aa0-112c8c9818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[features_len//3], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[features_len-features_len//3], name=\"deep_input\")\n",
    "hidden1_ = keras.layers.Dense(5, activation=\"selu\")(input_B)\n",
    "hidden2_ = keras.layers.Dense(3, activation=\"selu\")(hidden1_)\n",
    "concat_ = keras.layers.concatenate([input_A, hidden2_])\n",
    "output_ = keras.layers.Dense(1,activation='sigmoid')(concat_)\n",
    "model_combine = keras.Model(inputs=[input_A, input_B], outputs=[output_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42101c49-463c-474c-923c-9737282d05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3b13151-b014-40b9-937f-0a9d283ab387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 1s 49ms/step - loss: 1.6223 - accuracy: 0.4747 - val_loss: 1.2785 - val_accuracy: 0.7222\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5714 - accuracy: 0.4848 - val_loss: 1.2633 - val_accuracy: 0.7222\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5384 - accuracy: 0.4848 - val_loss: 1.2506 - val_accuracy: 0.7222\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5106 - accuracy: 0.4848 - val_loss: 1.2398 - val_accuracy: 0.7222\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4838 - accuracy: 0.4949 - val_loss: 1.2300 - val_accuracy: 0.7222\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4597 - accuracy: 0.4949 - val_loss: 1.2212 - val_accuracy: 0.7222\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4330 - accuracy: 0.5051 - val_loss: 1.2103 - val_accuracy: 0.7222\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4082 - accuracy: 0.5051 - val_loss: 1.1991 - val_accuracy: 0.7222\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3847 - accuracy: 0.5051 - val_loss: 1.1878 - val_accuracy: 0.7222\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3605 - accuracy: 0.5051 - val_loss: 1.1764 - val_accuracy: 0.7222\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3368 - accuracy: 0.5051 - val_loss: 1.1643 - val_accuracy: 0.7222\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3139 - accuracy: 0.5051 - val_loss: 1.1514 - val_accuracy: 0.7222\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2890 - accuracy: 0.5051 - val_loss: 1.1381 - val_accuracy: 0.7222\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2654 - accuracy: 0.5152 - val_loss: 1.1266 - val_accuracy: 0.7222\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2418 - accuracy: 0.5152 - val_loss: 1.1143 - val_accuracy: 0.7222\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2184 - accuracy: 0.5152 - val_loss: 1.1022 - val_accuracy: 0.7222\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1961 - accuracy: 0.5253 - val_loss: 1.0905 - val_accuracy: 0.7222\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1738 - accuracy: 0.5253 - val_loss: 1.0796 - val_accuracy: 0.7222\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1512 - accuracy: 0.5253 - val_loss: 1.0684 - val_accuracy: 0.7222\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1292 - accuracy: 0.5253 - val_loss: 1.0569 - val_accuracy: 0.7222\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1087 - accuracy: 0.5253 - val_loss: 1.0461 - val_accuracy: 0.7222\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0857 - accuracy: 0.5354 - val_loss: 1.0345 - val_accuracy: 0.7222\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0646 - accuracy: 0.5354 - val_loss: 1.0211 - val_accuracy: 0.7222\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0427 - accuracy: 0.5354 - val_loss: 1.0083 - val_accuracy: 0.7222\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0221 - accuracy: 0.5354 - val_loss: 0.9961 - val_accuracy: 0.7222\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0014 - accuracy: 0.5556 - val_loss: 0.9841 - val_accuracy: 0.6667\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9804 - accuracy: 0.5758 - val_loss: 0.9720 - val_accuracy: 0.6667\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9603 - accuracy: 0.5859 - val_loss: 0.9605 - val_accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9414 - accuracy: 0.5960 - val_loss: 0.9487 - val_accuracy: 0.6667\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9209 - accuracy: 0.6061 - val_loss: 0.9368 - val_accuracy: 0.6667\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9013 - accuracy: 0.6061 - val_loss: 0.9247 - val_accuracy: 0.6667\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8820 - accuracy: 0.6061 - val_loss: 0.9131 - val_accuracy: 0.6667\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8617 - accuracy: 0.6061 - val_loss: 0.9017 - val_accuracy: 0.6667\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8423 - accuracy: 0.6061 - val_loss: 0.8894 - val_accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8238 - accuracy: 0.6061 - val_loss: 0.8769 - val_accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8058 - accuracy: 0.6061 - val_loss: 0.8655 - val_accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7860 - accuracy: 0.6061 - val_loss: 0.8543 - val_accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7673 - accuracy: 0.6162 - val_loss: 0.8429 - val_accuracy: 0.6667\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7503 - accuracy: 0.6263 - val_loss: 0.8318 - val_accuracy: 0.6667\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7309 - accuracy: 0.6263 - val_loss: 0.8210 - val_accuracy: 0.6667\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7150 - accuracy: 0.6364 - val_loss: 0.8101 - val_accuracy: 0.6667\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6978 - accuracy: 0.6364 - val_loss: 0.7996 - val_accuracy: 0.6667\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.6364 - val_loss: 0.7891 - val_accuracy: 0.6667\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6652 - accuracy: 0.6364 - val_loss: 0.7789 - val_accuracy: 0.6667\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6493 - accuracy: 0.6465 - val_loss: 0.7682 - val_accuracy: 0.6667\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6341 - accuracy: 0.6667 - val_loss: 0.7585 - val_accuracy: 0.6667\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6185 - accuracy: 0.6667 - val_loss: 0.7496 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6050 - accuracy: 0.6768 - val_loss: 0.7410 - val_accuracy: 0.6667\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5888 - accuracy: 0.6768 - val_loss: 0.7321 - val_accuracy: 0.6667\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5747 - accuracy: 0.7172 - val_loss: 0.7235 - val_accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.7273 - val_loss: 0.7150 - val_accuracy: 0.6667\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5480 - accuracy: 0.7475 - val_loss: 0.7069 - val_accuracy: 0.6667\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.7576 - val_loss: 0.6996 - val_accuracy: 0.6111\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.7677 - val_loss: 0.6923 - val_accuracy: 0.6111\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5100 - accuracy: 0.7980 - val_loss: 0.6851 - val_accuracy: 0.6111\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4980 - accuracy: 0.7980 - val_loss: 0.6783 - val_accuracy: 0.6111\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4880 - accuracy: 0.7980 - val_loss: 0.6723 - val_accuracy: 0.6111\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.7980 - val_loss: 0.6678 - val_accuracy: 0.6111\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.7980 - val_loss: 0.6617 - val_accuracy: 0.6111\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.8283 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4456 - accuracy: 0.8384 - val_loss: 0.6509 - val_accuracy: 0.6111\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8485 - val_loss: 0.6459 - val_accuracy: 0.6111\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8485 - val_loss: 0.6413 - val_accuracy: 0.6111\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4172 - accuracy: 0.8586 - val_loss: 0.6375 - val_accuracy: 0.6111\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4079 - accuracy: 0.8586 - val_loss: 0.6347 - val_accuracy: 0.6111\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.8586 - val_loss: 0.6312 - val_accuracy: 0.6111\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3917 - accuracy: 0.8586 - val_loss: 0.6289 - val_accuracy: 0.6667\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3842 - accuracy: 0.8586 - val_loss: 0.6266 - val_accuracy: 0.7222\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3755 - accuracy: 0.8586 - val_loss: 0.6243 - val_accuracy: 0.7222\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3681 - accuracy: 0.8586 - val_loss: 0.6219 - val_accuracy: 0.7222\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.8485 - val_loss: 0.6195 - val_accuracy: 0.7222\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8586 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3476 - accuracy: 0.8586 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3412 - accuracy: 0.8687 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3353 - accuracy: 0.8687 - val_loss: 0.6119 - val_accuracy: 0.7222\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3285 - accuracy: 0.8687 - val_loss: 0.6100 - val_accuracy: 0.7222\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.8788 - val_loss: 0.6086 - val_accuracy: 0.7222\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.8788 - val_loss: 0.6075 - val_accuracy: 0.7222\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3119 - accuracy: 0.8889 - val_loss: 0.6070 - val_accuracy: 0.7222\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3071 - accuracy: 0.8889 - val_loss: 0.6057 - val_accuracy: 0.7222\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3016 - accuracy: 0.8788 - val_loss: 0.6049 - val_accuracy: 0.7222\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 0.8889 - val_loss: 0.6037 - val_accuracy: 0.7222\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2921 - accuracy: 0.8788 - val_loss: 0.6035 - val_accuracy: 0.7222\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2866 - accuracy: 0.8788 - val_loss: 0.6026 - val_accuracy: 0.7222\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2820 - accuracy: 0.8788 - val_loss: 0.6020 - val_accuracy: 0.7222\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2783 - accuracy: 0.8788 - val_loss: 0.6019 - val_accuracy: 0.6667\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2735 - accuracy: 0.8788 - val_loss: 0.6012 - val_accuracy: 0.7222\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2688 - accuracy: 0.8788 - val_loss: 0.6011 - val_accuracy: 0.7222\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2649 - accuracy: 0.8889 - val_loss: 0.6008 - val_accuracy: 0.7222\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2597 - accuracy: 0.8788 - val_loss: 0.6010 - val_accuracy: 0.7222\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.8889 - val_loss: 0.6008 - val_accuracy: 0.7222\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2514 - accuracy: 0.9091 - val_loss: 0.6007 - val_accuracy: 0.7222\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2475 - accuracy: 0.9091 - val_loss: 0.6006 - val_accuracy: 0.7222\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2441 - accuracy: 0.9091 - val_loss: 0.6021 - val_accuracy: 0.7222\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 0.9091 - val_loss: 0.6023 - val_accuracy: 0.7222\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2362 - accuracy: 0.9091 - val_loss: 0.6033 - val_accuracy: 0.7222\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2328 - accuracy: 0.9091 - val_loss: 0.6035 - val_accuracy: 0.7222\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2295 - accuracy: 0.9091 - val_loss: 0.6040 - val_accuracy: 0.7222\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2262 - accuracy: 0.9192 - val_loss: 0.6037 - val_accuracy: 0.7222\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2233 - accuracy: 0.9192 - val_loss: 0.6027 - val_accuracy: 0.7222\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2190 - accuracy: 0.9293 - val_loss: 0.6029 - val_accuracy: 0.7222\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2158 - accuracy: 0.9293 - val_loss: 0.6039 - val_accuracy: 0.7222\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2132 - accuracy: 0.9394 - val_loss: 0.6039 - val_accuracy: 0.7222\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2098 - accuracy: 0.9495 - val_loss: 0.6040 - val_accuracy: 0.7222\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2077 - accuracy: 0.9495 - val_loss: 0.6039 - val_accuracy: 0.7222\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2034 - accuracy: 0.9495 - val_loss: 0.6045 - val_accuracy: 0.7222\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2014 - accuracy: 0.9596 - val_loss: 0.6056 - val_accuracy: 0.7222\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1981 - accuracy: 0.9596 - val_loss: 0.6058 - val_accuracy: 0.7222\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1954 - accuracy: 0.9596 - val_loss: 0.6062 - val_accuracy: 0.7222\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1931 - accuracy: 0.9596 - val_loss: 0.6061 - val_accuracy: 0.7222\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9596 - val_loss: 0.6072 - val_accuracy: 0.7222\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1876 - accuracy: 0.9596 - val_loss: 0.6078 - val_accuracy: 0.7222\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9596 - val_loss: 0.6090 - val_accuracy: 0.7222\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1823 - accuracy: 0.9596 - val_loss: 0.6097 - val_accuracy: 0.7222\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.9697 - val_loss: 0.6108 - val_accuracy: 0.7222\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1768 - accuracy: 0.9697 - val_loss: 0.6122 - val_accuracy: 0.7222\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1749 - accuracy: 0.9697 - val_loss: 0.6139 - val_accuracy: 0.7222\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1725 - accuracy: 0.9697 - val_loss: 0.6159 - val_accuracy: 0.7222\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1702 - accuracy: 0.9697 - val_loss: 0.6173 - val_accuracy: 0.7222\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1682 - accuracy: 0.9697 - val_loss: 0.6187 - val_accuracy: 0.7222\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1660 - accuracy: 0.9697 - val_loss: 0.6201 - val_accuracy: 0.7222\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9697 - val_loss: 0.6214 - val_accuracy: 0.7222\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1618 - accuracy: 0.9697 - val_loss: 0.6232 - val_accuracy: 0.7222\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1596 - accuracy: 0.9697 - val_loss: 0.6245 - val_accuracy: 0.7222\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 0.9697 - val_loss: 0.6263 - val_accuracy: 0.7222\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9697 - val_loss: 0.6268 - val_accuracy: 0.7222\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1534 - accuracy: 0.9697 - val_loss: 0.6278 - val_accuracy: 0.7222\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1509 - accuracy: 0.9697 - val_loss: 0.6293 - val_accuracy: 0.7222\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1490 - accuracy: 0.9697 - val_loss: 0.6312 - val_accuracy: 0.7222\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1474 - accuracy: 0.9697 - val_loss: 0.6334 - val_accuracy: 0.7222\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1453 - accuracy: 0.9697 - val_loss: 0.6344 - val_accuracy: 0.7222\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9697 - val_loss: 0.6350 - val_accuracy: 0.7222\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1420 - accuracy: 0.9697 - val_loss: 0.6374 - val_accuracy: 0.7222\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1399 - accuracy: 0.9697 - val_loss: 0.6389 - val_accuracy: 0.7222\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1380 - accuracy: 0.9697 - val_loss: 0.6404 - val_accuracy: 0.7222\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1365 - accuracy: 0.9697 - val_loss: 0.6414 - val_accuracy: 0.7222\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1345 - accuracy: 0.9798 - val_loss: 0.6432 - val_accuracy: 0.7222\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1328 - accuracy: 0.9798 - val_loss: 0.6437 - val_accuracy: 0.7222\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1309 - accuracy: 0.9798 - val_loss: 0.6440 - val_accuracy: 0.7222\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1291 - accuracy: 0.9798 - val_loss: 0.6455 - val_accuracy: 0.7222\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1280 - accuracy: 0.9798 - val_loss: 0.6466 - val_accuracy: 0.7222\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1258 - accuracy: 0.9798 - val_loss: 0.6483 - val_accuracy: 0.7222\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9798 - val_loss: 0.6499 - val_accuracy: 0.7222\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1227 - accuracy: 0.9798 - val_loss: 0.6511 - val_accuracy: 0.7222\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1210 - accuracy: 0.9798 - val_loss: 0.6530 - val_accuracy: 0.7222\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1191 - accuracy: 0.9798 - val_loss: 0.6540 - val_accuracy: 0.7222\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1178 - accuracy: 0.9899 - val_loss: 0.6557 - val_accuracy: 0.7222\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1158 - accuracy: 0.9899 - val_loss: 0.6573 - val_accuracy: 0.7222\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1142 - accuracy: 0.9899 - val_loss: 0.6578 - val_accuracy: 0.7222\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1128 - accuracy: 0.9899 - val_loss: 0.6594 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1e47352d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combine.fit([train_features_A, train_features_B],train_target,batch_size = 20, epochs=150,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcebb4f3-364e-4e5c-9d4e-4fa6ee8e84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir='output/logs',histogram_freq=1,embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c24aeda-2931-4659-bf35-53309398fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1113 - accuracy: 0.9899 - val_loss: 0.6605 - val_accuracy: 0.7222\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1098 - accuracy: 0.9899 - val_loss: 0.6610 - val_accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1079 - accuracy: 0.9899 - val_loss: 0.6624 - val_accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1067 - accuracy: 0.9899 - val_loss: 0.6633 - val_accuracy: 0.7222\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.1052 - accuracy: 0.9899 - val_loss: 0.6647 - val_accuracy: 0.7222\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1036 - accuracy: 0.9899 - val_loss: 0.6665 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1023 - accuracy: 0.9899 - val_loss: 0.6671 - val_accuracy: 0.7222\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1003 - accuracy: 0.9899 - val_loss: 0.6682 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0990 - accuracy: 0.9899 - val_loss: 0.6711 - val_accuracy: 0.7222\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0972 - accuracy: 0.9899 - val_loss: 0.6734 - val_accuracy: 0.7222\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0960 - accuracy: 0.9899 - val_loss: 0.6748 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0939 - accuracy: 0.9899 - val_loss: 0.6756 - val_accuracy: 0.7222\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0926 - accuracy: 0.9899 - val_loss: 0.6765 - val_accuracy: 0.7222\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0917 - accuracy: 0.9899 - val_loss: 0.6776 - val_accuracy: 0.7222\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0902 - accuracy: 0.9899 - val_loss: 0.6803 - val_accuracy: 0.7222\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.7222\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.7222\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.7222\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.7222\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.7222\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.7222\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.6667\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.7682 - val_accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.7222\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.7222\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.7222\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.7222\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.7222\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7222\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7222\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7222\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.7222\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7222\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.7222\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.7222\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.7222\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.7222\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.7222\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.8409 - val_accuracy: 0.7222\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.7222\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.8512 - val_accuracy: 0.7222\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.7222\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.7222\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.7222\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.7222\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.7222\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.7222\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.7222\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.6667\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.6667\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.9195 - val_accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.6667\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.6667\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.6667\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.6667\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.9830 - val_accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.0069 - val_accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.6667\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.6667\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.6667\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.6667\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.6667\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.0334 - val_accuracy: 0.6667\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.6667\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.6667\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.0484 - val_accuracy: 0.6667\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.6667\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.0703 - val_accuracy: 0.6667\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.6667\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.6667\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.6667\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.0983 - val_accuracy: 0.6667\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1023 - val_accuracy: 0.6667\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.6667\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1180 - val_accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.6667\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.6667\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.6667\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.6667\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1429 - val_accuracy: 0.6667\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.6667\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.6667\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.6667\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.6667\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1707 - val_accuracy: 0.6667\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.6667\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.6667\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1876 - val_accuracy: 0.6667\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.6667\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.6667\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.6667\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.6667\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.6667\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2143 - val_accuracy: 0.6667\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.6667\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2214 - val_accuracy: 0.6667\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.6667\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.6667\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.6667\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2369 - val_accuracy: 0.6667\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2431 - val_accuracy: 0.6667\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2466 - val_accuracy: 0.6667\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2522 - val_accuracy: 0.6667\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2558 - val_accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.6667\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2724 - val_accuracy: 0.6667\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2747 - val_accuracy: 0.6667\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.6667\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2838 - val_accuracy: 0.6667\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2898 - val_accuracy: 0.6667\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2951 - val_accuracy: 0.6667\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.6667\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.6667\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3112 - val_accuracy: 0.6667\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3150 - val_accuracy: 0.6667\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3206 - val_accuracy: 0.6667\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.6667\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.6667\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3335 - val_accuracy: 0.6667\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3394 - val_accuracy: 0.6667\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3462 - val_accuracy: 0.6667\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3514 - val_accuracy: 0.6667\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.7222\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3619 - val_accuracy: 0.7222\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3674 - val_accuracy: 0.7222\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3727 - val_accuracy: 0.7222\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.7222\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.7222\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3925 - val_accuracy: 0.7222\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4006 - val_accuracy: 0.7222\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4058 - val_accuracy: 0.7222\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4113 - val_accuracy: 0.7222\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4162 - val_accuracy: 0.7222\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4232 - val_accuracy: 0.7222\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4286 - val_accuracy: 0.7222\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4367 - val_accuracy: 0.7222\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4428 - val_accuracy: 0.7222\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.7222\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.7222\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4574 - val_accuracy: 0.7222\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4627 - val_accuracy: 0.7222\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.7222\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4742 - val_accuracy: 0.7222\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4798 - val_accuracy: 0.7222\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4868 - val_accuracy: 0.7222\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.7222\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.9549e-04 - accuracy: 1.0000 - val_loss: 1.4985 - val_accuracy: 0.7222\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.5795e-04 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.7222\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2891e-04 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.7222\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9902e-04 - accuracy: 1.0000 - val_loss: 1.5124 - val_accuracy: 0.7222\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.7391e-04 - accuracy: 1.0000 - val_loss: 1.5191 - val_accuracy: 0.7222\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4688e-04 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.7222\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 8.1863e-04 - accuracy: 1.0000 - val_loss: 1.5279 - val_accuracy: 0.7222\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.9459e-04 - accuracy: 1.0000 - val_loss: 1.5315 - val_accuracy: 0.7222\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.6663e-04 - accuracy: 1.0000 - val_loss: 1.5395 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1c861d2d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combine.fit((train_features_A, train_features_B),train_target,batch_size = 20, epochs=200,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target),\n",
    "                  callbacks=tensorboard_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d88ad5-9d7f-4e28-ae0c-fef1842c7b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0451e8-47f4-433b-b003-2799ee796a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0b045-47a7-49cb-b449-821f36e29925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1fca7e-dd22-4c1a-a602-5bfe23513340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
