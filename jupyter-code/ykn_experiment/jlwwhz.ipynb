{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292c7995-0d36-49da-ba08-0b05f66b1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LassoCV,RidgeCV\n",
    "from scipy.stats import ttest_ind, levene\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold,ShuffleSplit,cross_val_score,RepeatedKFold\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a235bbc0-3120-496c-a897-18d304a15313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LA = pd.read_csv(\"input/LA_total.csv\",index_col=0)\n",
    "data_XA = pd.read_csv(\"input/XA_total.csv\",index_col=0)\n",
    "\n",
    "\n",
    "data_LA_ = pd.DataFrame()\n",
    "columns_LA = data_LA.columns\n",
    "for col in columns_LA:\n",
    "    try:\n",
    "        df = data_LA[col].astype(np.float64)\n",
    "        data_LA_ = pd.concat([data_LA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "    \n",
    "data_XA_ = pd.DataFrame()\n",
    "columns_XA = data_XA.columns\n",
    "for col in columns_XA:\n",
    "    try:\n",
    "        df = data_XA[col].astype(np.float64)\n",
    "        data_XA_ = pd.concat([data_XA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "\n",
    "# 方差齐性\n",
    "index_ = []\n",
    "for col in data_LA_.columns:\n",
    "    if levene(data_LA_[col],data_XA_[col])[1] > 0.05:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col])[1] < 0.05:\n",
    "            index_.append(col)\n",
    "    else:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col],equal_var=False)[1] < 0.05:\n",
    "            index_.append(col)\n",
    "\n",
    "\n",
    "data_L_T = data_LA_[index_]\n",
    "data_X_T = data_XA_[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174e1e5d-6f5b-476e-b9f9-4141bce75599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MVI</th>\n",
       "      <th>diagnosticsImage-originalMean</th>\n",
       "      <th>diagnosticsImage-originalMinimum</th>\n",
       "      <th>diagnosticsMask-originalVoxelNum</th>\n",
       "      <th>originalshapeFlatness</th>\n",
       "      <th>originalshapeLeastAxisLength</th>\n",
       "      <th>originalshapeMaximum2DDiameterRow</th>\n",
       "      <th>originalshapeMaximum2DDiameterSlice</th>\n",
       "      <th>originalshapeMeshVolume</th>\n",
       "      <th>originalshapeMinorAxisLength</th>\n",
       "      <th>...</th>\n",
       "      <th>wavelet-LLLglszmGrayLevelNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmLowGrayLevelZoneEmphasis</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformity</th>\n",
       "      <th>wavelet-LLLglszmSizeZoneNonUniformityNormalized</th>\n",
       "      <th>wavelet-LLLglszmSmallAreaEmphasis</th>\n",
       "      <th>wavelet-LLLglszmZoneEntropy</th>\n",
       "      <th>wavelet-LLLglszmZonePercentage</th>\n",
       "      <th>wavelet-LLLngtdmCoarseness</th>\n",
       "      <th>wavelet-LLLngtdmContrast</th>\n",
       "      <th>wavelet-LLLngtdmStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-572.468909</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.318967</td>\n",
       "      <td>25.702492</td>\n",
       "      <td>1283.212372</td>\n",
       "      <td>10.044991</td>\n",
       "      <td>...</td>\n",
       "      <td>8.368421</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>95.105263</td>\n",
       "      <td>0.500554</td>\n",
       "      <td>0.735249</td>\n",
       "      <td>5.806156</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.051376</td>\n",
       "      <td>0.151701</td>\n",
       "      <td>39.193379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-614.479883</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>0.325347</td>\n",
       "      <td>11.606881</td>\n",
       "      <td>41.031098</td>\n",
       "      <td>18.722147</td>\n",
       "      <td>3211.358643</td>\n",
       "      <td>16.271385</td>\n",
       "      <td>...</td>\n",
       "      <td>17.169935</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>113.405229</td>\n",
       "      <td>0.370605</td>\n",
       "      <td>0.629734</td>\n",
       "      <td>6.051654</td>\n",
       "      <td>0.363853</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>5.268588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-519.434062</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.470212</td>\n",
       "      <td>9.947152</td>\n",
       "      <td>23.717578</td>\n",
       "      <td>22.359344</td>\n",
       "      <td>1902.632141</td>\n",
       "      <td>13.088408</td>\n",
       "      <td>...</td>\n",
       "      <td>19.300429</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>88.622318</td>\n",
       "      <td>0.380353</td>\n",
       "      <td>0.640048</td>\n",
       "      <td>5.582590</td>\n",
       "      <td>0.398291</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>0.055859</td>\n",
       "      <td>4.511572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-561.705713</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.117304</td>\n",
       "      <td>2.174066</td>\n",
       "      <td>11.028646</td>\n",
       "      <td>1.229837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.921928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>1.060667</td>\n",
       "      <td>4.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1011.874072</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.467858</td>\n",
       "      <td>8.351445</td>\n",
       "      <td>15.605997</td>\n",
       "      <td>16.102215</td>\n",
       "      <td>343.855290</td>\n",
       "      <td>14.703789</td>\n",
       "      <td>...</td>\n",
       "      <td>4.296703</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>50.230769</td>\n",
       "      <td>0.551986</td>\n",
       "      <td>0.769669</td>\n",
       "      <td>5.226439</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.135631</td>\n",
       "      <td>0.145841</td>\n",
       "      <td>43.031788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-618.750804</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>21.184937</td>\n",
       "      <td>87.116639</td>\n",
       "      <td>50.781805</td>\n",
       "      <td>13139.636920</td>\n",
       "      <td>37.892768</td>\n",
       "      <td>...</td>\n",
       "      <td>132.664148</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>392.306465</td>\n",
       "      <td>0.329392</td>\n",
       "      <td>0.591371</td>\n",
       "      <td>5.602077</td>\n",
       "      <td>0.391776</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>0.830082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-651.740777</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>0.554254</td>\n",
       "      <td>14.544836</td>\n",
       "      <td>26.468711</td>\n",
       "      <td>27.300936</td>\n",
       "      <td>4666.411388</td>\n",
       "      <td>19.105224</td>\n",
       "      <td>...</td>\n",
       "      <td>23.406667</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>100.653333</td>\n",
       "      <td>0.335511</td>\n",
       "      <td>0.596677</td>\n",
       "      <td>5.717587</td>\n",
       "      <td>0.278552</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.074280</td>\n",
       "      <td>1.334465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-547.092129</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.454595</td>\n",
       "      <td>7.835145</td>\n",
       "      <td>21.224320</td>\n",
       "      <td>16.322570</td>\n",
       "      <td>1416.078392</td>\n",
       "      <td>13.758645</td>\n",
       "      <td>...</td>\n",
       "      <td>8.823204</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>60.889503</td>\n",
       "      <td>0.336406</td>\n",
       "      <td>0.590477</td>\n",
       "      <td>6.042421</td>\n",
       "      <td>0.476316</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.211781</td>\n",
       "      <td>10.460162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-475.194220</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.229733</td>\n",
       "      <td>6.209354</td>\n",
       "      <td>26.476129</td>\n",
       "      <td>12.483830</td>\n",
       "      <td>892.256973</td>\n",
       "      <td>10.614482</td>\n",
       "      <td>...</td>\n",
       "      <td>8.042945</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>67.638037</td>\n",
       "      <td>0.414957</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>5.689176</td>\n",
       "      <td>0.537954</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.338459</td>\n",
       "      <td>6.332368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-600.984933</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.614269</td>\n",
       "      <td>7.908654</td>\n",
       "      <td>17.802055</td>\n",
       "      <td>12.827708</td>\n",
       "      <td>839.388805</td>\n",
       "      <td>11.355911</td>\n",
       "      <td>...</td>\n",
       "      <td>7.411765</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>57.250000</td>\n",
       "      <td>0.420956</td>\n",
       "      <td>0.673088</td>\n",
       "      <td>5.633501</td>\n",
       "      <td>0.521073</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>11.364464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MVI  diagnosticsImage-originalMean  diagnosticsImage-originalMinimum  \\\n",
       "L27  0.0                    -572.468909                           -1024.0   \n",
       "X14  1.0                    -614.479883                           -1024.0   \n",
       "L20  0.0                    -519.434062                           -1024.0   \n",
       "X13  1.0                    -561.705713                           -1024.0   \n",
       "X32  1.0                   -1011.874072                           -3024.0   \n",
       "..   ...                            ...                               ...   \n",
       "L45  0.0                    -618.750804                           -1024.0   \n",
       "L57  0.0                    -651.740777                           -1024.0   \n",
       "X9   1.0                    -547.092129                           -1024.0   \n",
       "X5   1.0                    -475.194220                           -1024.0   \n",
       "x20  1.0                    -600.984933                           -1024.0   \n",
       "\n",
       "     diagnosticsMask-originalVoxelNum  originalshapeFlatness  \\\n",
       "L27                             310.0               0.000000   \n",
       "X14                             841.0               0.325347   \n",
       "L20                             585.0               0.470212   \n",
       "X13                               5.0               0.000000   \n",
       "X32                             144.0               0.467858   \n",
       "..                                ...                    ...   \n",
       "L45                            3040.0               0.184973   \n",
       "L57                            1077.0               0.554254   \n",
       "X9                              380.0               0.454595   \n",
       "X5                              303.0               0.229733   \n",
       "x20                             261.0               0.614269   \n",
       "\n",
       "     originalshapeLeastAxisLength  originalshapeMaximum2DDiameterRow  \\\n",
       "L27                      0.000000                          22.318967   \n",
       "X14                     11.606881                          41.031098   \n",
       "L20                      9.947152                          23.717578   \n",
       "X13                      0.000000                           8.117304   \n",
       "X32                      8.351445                          15.605997   \n",
       "..                            ...                                ...   \n",
       "L45                     21.184937                          87.116639   \n",
       "L57                     14.544836                          26.468711   \n",
       "X9                       7.835145                          21.224320   \n",
       "X5                       6.209354                          26.476129   \n",
       "x20                      7.908654                          17.802055   \n",
       "\n",
       "     originalshapeMaximum2DDiameterSlice  originalshapeMeshVolume  \\\n",
       "L27                            25.702492              1283.212372   \n",
       "X14                            18.722147              3211.358643   \n",
       "L20                            22.359344              1902.632141   \n",
       "X13                             2.174066                11.028646   \n",
       "X32                            16.102215               343.855290   \n",
       "..                                   ...                      ...   \n",
       "L45                            50.781805             13139.636920   \n",
       "L57                            27.300936              4666.411388   \n",
       "X9                             16.322570              1416.078392   \n",
       "X5                             12.483830               892.256973   \n",
       "x20                            12.827708               839.388805   \n",
       "\n",
       "     originalshapeMinorAxisLength  ...  \\\n",
       "L27                     10.044991  ...   \n",
       "X14                     16.271385  ...   \n",
       "L20                     13.088408  ...   \n",
       "X13                      1.229837  ...   \n",
       "X32                     14.703789  ...   \n",
       "..                            ...  ...   \n",
       "L45                     37.892768  ...   \n",
       "L57                     19.105224  ...   \n",
       "X9                      13.758645  ...   \n",
       "X5                      10.614482  ...   \n",
       "x20                     11.355911  ...   \n",
       "\n",
       "     wavelet-LLLglszmGrayLevelNonUniformity  \\\n",
       "L27                                8.368421   \n",
       "X14                               17.169935   \n",
       "L20                               19.300429   \n",
       "X13                                1.400000   \n",
       "X32                                4.296703   \n",
       "..                                      ...   \n",
       "L45                              132.664148   \n",
       "L57                               23.406667   \n",
       "X9                                 8.823204   \n",
       "X5                                 8.042945   \n",
       "x20                                7.411765   \n",
       "\n",
       "     wavelet-LLLglszmLowGrayLevelZoneEmphasis  \\\n",
       "L27                                  0.009067   \n",
       "X14                                  0.008837   \n",
       "L20                                  0.010607   \n",
       "X13                                  0.327778   \n",
       "X32                                  0.022263   \n",
       "..                                        ...   \n",
       "L45                                  0.007296   \n",
       "L57                                  0.013062   \n",
       "X9                                   0.023080   \n",
       "X5                                   0.014268   \n",
       "x20                                  0.010612   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformity  \\\n",
       "L27                              95.105263   \n",
       "X14                             113.405229   \n",
       "L20                              88.622318   \n",
       "X13                               5.000000   \n",
       "X32                              50.230769   \n",
       "..                                     ...   \n",
       "L45                             392.306465   \n",
       "L57                             100.653333   \n",
       "X9                               60.889503   \n",
       "X5                               67.638037   \n",
       "x20                              57.250000   \n",
       "\n",
       "     wavelet-LLLglszmSizeZoneNonUniformityNormalized  \\\n",
       "L27                                         0.500554   \n",
       "X14                                         0.370605   \n",
       "L20                                         0.380353   \n",
       "X13                                         1.000000   \n",
       "X32                                         0.551986   \n",
       "..                                               ...   \n",
       "L45                                         0.329392   \n",
       "L57                                         0.335511   \n",
       "X9                                          0.336406   \n",
       "X5                                          0.414957   \n",
       "x20                                         0.420956   \n",
       "\n",
       "     wavelet-LLLglszmSmallAreaEmphasis  wavelet-LLLglszmZoneEntropy  \\\n",
       "L27                           0.735249                     5.806156   \n",
       "X14                           0.629734                     6.051654   \n",
       "L20                           0.640048                     5.582590   \n",
       "X13                           1.000000                     1.921928   \n",
       "X32                           0.769669                     5.226439   \n",
       "..                                 ...                          ...   \n",
       "L45                           0.591371                     5.602077   \n",
       "L57                           0.596677                     5.717587   \n",
       "X9                            0.590477                     6.042421   \n",
       "X5                            0.663182                     5.689176   \n",
       "x20                           0.673088                     5.633501   \n",
       "\n",
       "     wavelet-LLLglszmZonePercentage  wavelet-LLLngtdmCoarseness  \\\n",
       "L27                        0.612903                    0.051376   \n",
       "X14                        0.363853                    0.010544   \n",
       "L20                        0.398291                    0.013391   \n",
       "X13                        1.000000                    0.342857   \n",
       "X32                        0.631944                    0.135631   \n",
       "..                              ...                         ...   \n",
       "L45                        0.391776                    0.002724   \n",
       "L57                        0.278552                    0.006583   \n",
       "X9                         0.476316                    0.028226   \n",
       "X5                         0.537954                    0.023778   \n",
       "x20                        0.521073                    0.033755   \n",
       "\n",
       "     wavelet-LLLngtdmContrast  wavelet-LLLngtdmStrength  \n",
       "L27                  0.151701                 39.193379  \n",
       "X14                  0.091911                  5.268588  \n",
       "L20                  0.055859                  4.511572  \n",
       "X13                  1.060667                  4.837209  \n",
       "X32                  0.145841                 43.031788  \n",
       "..                        ...                       ...  \n",
       "L45                  0.027985                  0.830082  \n",
       "L57                  0.074280                  1.334465  \n",
       "X9                   0.211781                 10.460162  \n",
       "X5                   0.338459                  6.332368  \n",
       "x20                  0.192491                 11.364464  \n",
       "\n",
       "[138 rows x 460 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_L_T,data_X_T])\n",
    "data = shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c237d94-bc0e-40ea-895c-d444c59f812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data.iloc[:, 0]\n",
    "features = data.iloc[:,1:]\n",
    "\n",
    "features\n",
    "target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90f3976-1b9b-470c-96d6-c6b93589aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 459)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer = StandardScaler()\n",
    "features_SS = transfer.fit_transform(features)\n",
    "\n",
    "features_SS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7c3c17-ffd4-458d-b3ed-412e22f5937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alphas_ = np.logspace(-2,0,300)\n",
    "\n",
    "\n",
    "# lassocv = LassoCV(alphas = alphas_,cv = 10,max_iter = 100000)\n",
    "# sfm = SelectFromModel(lassocv)\n",
    "# sfm.fit_transform(features_SS, target)\n",
    "# # features = features[features.columns[lassocv.coef_!=0]]\n",
    "# # print(len(features.columns))\n",
    "# selected_features = sfm.get_support(indices=True)\n",
    "# print(\"Selected features:\", selected_features)\n",
    "# all_features = [f'Feature_{i+1}' for i in range(selected_features.shape[1])]\n",
    "# # features_SS =features_SS[:, pd.DataFrame(features_SS).columns[lassocv.coef_!=0]]\n",
    "# all_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc88f385-0c9c-4fa0-b579-5a281db2c893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 459)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_SS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ebbfcd-9f8c-4e53-bc60-7944eaae02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "\n",
    "# # 初始化 RidgeCV 模型，指定一组 alpha 值\n",
    "# alphas_ = np.logspace(-2,0,300)\n",
    "# ridge_cv = RidgeCV(alphas=alphas_)\n",
    "\n",
    "# # 使用 SelectFromModel 进行特征选择\n",
    "# sfm = SelectFromModel(ridge_cv)\n",
    "# sfm.fit(features_SS, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324d9b61-cb05-445e-85a4-fc21cffbcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 获取选择的特征索引\n",
    "# selected_features = sfm.get_support(indices=True)\n",
    "\n",
    "# # 打印选择的特征索引\n",
    "# print(\"Selected features indices:\", selected_features)\n",
    "# features_SS = pd.DataFrame(features_SS).iloc[:, selected_features]\n",
    "\n",
    "# features_SS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a346f4-096c-4a53-b249-165e4f834263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221a7a5-a6c1-4d74-ae60-d8a156e998ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d50ca3-ea53-4d2e-b5cf-c8850d5228df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d92da3c6-15a3-4cfd-a990-a35f784d54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ae857f-7d05-435c-bb5d-ff2e7b44904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lda = lda.fit_transform(features_SS,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd540e6a-9ec6-4241-b938-6cf53badd09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3074c99e-1eb0-4b6e-bf79-fa46f8840ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features_lda, target, \n",
    "    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f69f07-e240-4cd6-b6b4-7d78f62888af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea263245-3d75-4207-b6f2-8c7ed1c9145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29da1a3b-2f82-4acb-8e4b-f9f439c850fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#邏輯回歸\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "\n",
    "log.fit(train_features, train_target)\n",
    "test_predict = log.predict(test_features)\n",
    "# print(test_target)\n",
    "# print(test_predict)\n",
    "log.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be60bbb-ab27-4c1e-900d-f0f130410a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8261d8-c0c0-4520-803d-3fe11b3a5ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba434ccb-b5f4-43ee-bd3b-88b1126c82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc5523d0-4694-468c-bdcb-2a02872666e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d5d5cf-8c90-447e-ba68-b7826f9d04f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = tree_clf.predict(test_features)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1ffa795-f5e3-4fa5-acc4-899924ef7513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a4a0343-c7fb-4d48-8678-e9bb53416f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "plot_tree(tree_clf) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210a33e-b2a6-4fd9-8a77-049a8008359e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75336cda-21c3-43a3-8026-09656ffd57f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04027591-e702-403c-b89d-e204567e27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#randomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "model_rf = model.fit(train_features,train_target)\n",
    "score_rf = model_rf.score(test_features,test_target)\n",
    "print(score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31050c9a-0e24-4c32-83c4-55af3bd64ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4a943-f9ef-4036-87b2-0b4be7ed641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c22ae7-dbe5-4363-b612-fddb15ebc216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1)\n",
    "svc_linear.fit(train_features, train_target)\n",
    "test_predict = svc_linear.predict(test_features)\n",
    "svc_linear.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e29035d-4ab6-4bad-ab91-d95070ebd363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_linear.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168cfb3-e28c-48ef-b664-a61479d83afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6061b-5fa8-4de4-b8e6-a957429843c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "337c82d5-6e1b-40c5-9a4c-c2e6475bca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0)\n",
    "svc_rbf.fit(train_features, train_target)\n",
    "test_predict = svc_rbf.predict(test_features)\n",
    "svc_rbf.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22009fa8-dd75-48c4-894f-240c03ec7c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fd174-ca32-4247-a109-6677522a4b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104b43a-386c-4aa9-90b0-a7842eed424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a939507-f567-4f81-8f1d-46d6722d09a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0)\n",
    "svc_poly.fit(train_features, train_target)\n",
    "test_predict = svc_poly.predict(test_features)\n",
    "svc_poly.score(test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85372590-3bd5-4b00-ace8-a3c7e49bc4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27842b5-09e0-4e72-a350-317799fd3ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd1216-5b4f-4bb1-bb6d-12848e503869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa290bb2-bb4d-48bd-8740-95e3f13c7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9761904761904762\n",
      "SVC 0.9761904761904762\n",
      "SVC 0.8333333333333334\n",
      "SVC 0.9761904761904762\n",
      "VotingClassifier 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "#集成算法\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='hard')\n",
    "#, ('tree', tree_clf)\n",
    "voting_clf.fit(train_features, train_target)\n",
    "\n",
    "for clf in (log_clf, svc_linear,svc_poly,svc_rbf, voting_clf):\n",
    "    clf.fit(train_features, train_target)\n",
    "    print(clf.__class__.__name__, clf.score(test_features, test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7b1baa4-7abd-4074-a708-928528417710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762afe1b-db48-4293-93bf-117d50fdcc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f72f4-d3ef-4de0-a01b-8e6fbc937ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed4454a2-a600-4f9f-8f4e-34ea669cd7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9761904761904762\n",
      "SVC 0.9761904761904762\n",
      "SVC 0.8333333333333334\n",
      "SVC 0.9761904761904762\n",
      "VotingClassifier 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "     estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='soft')\n",
    "#, ('tree', tree_clf)\n",
    "voting_clf.fit(train_features, train_target)\n",
    "for clf in (log_clf,  svc_linear,svc_poly,svc_rbf, voting_clf):\n",
    "    clf.fit(train_features, train_target)\n",
    "    print(clf.__class__.__name__, clf.score(test_features, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cdc6cd6-76bb-4b13-84a5-feaaf3e52e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90446fa0-a7ef-4841-8694-62eb8ed70929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81e882c3-59d8-4f82-a840-d5f02a49ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "log_ensemble = LogisticRegression()\n",
    "\n",
    "stk_clf = StackingClassifier(\n",
    "      estimators=[('lr', log_clf), ('svc_l', svc_linear),\n",
    "                  ('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    final_estimator=log_ensemble)\n",
    "\n",
    "stk_clf.fit(train_features, train_target)\n",
    "\n",
    "stk_clf.score(test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce991f-bb9d-4b43-a754-80ec9cf3c431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86dd71-b00c-4a8c-9a81-3e64400a5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffb0a4-1fce-4a6c-80a0-c0afeb76580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c693954-c9b6-4d91-9662-12e0c6736134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464835164835166\n"
     ]
    }
   ],
   "source": [
    "rkf=RepeatedKFold(n_splits=10,n_repeats=10)\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression(penalty='l2',max_iter = 10000000,n_jobs=-1)\n",
    "svc_linear = SVC(kernel = \"linear\",max_iter=-1,probability=True)\n",
    "svc_poly = SVC(kernel=\"poly\",degree=3,coef0=0,probability=True)\n",
    "svc_rbf = SVC(kernel=\"rbf\",degree=3,coef0=0,probability=True)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "     estimators=[('lr', log_clf), ('svc_l', svc_linear),('svc_p',svc_poly),('svc_r',svc_rbf)],\n",
    "    voting='soft')\n",
    "sum_score = 0\n",
    "\n",
    "for train_index, test_index in rkf.split(features_lda):\n",
    "    X_train =pd.DataFrame(features_lda).iloc[train_index]\n",
    "    X_test =pd.DataFrame(features_lda).iloc[test_index]\n",
    "    # print(train_index)\n",
    "    # print(test_index)\n",
    "    y_train =pd.DataFrame(target).iloc[train_index]\n",
    "    y_test =pd.DataFrame(target).iloc[test_index]\n",
    "    model_svm = voting_clf.fit(X_train,y_train)\n",
    "    score_svm=model_svm.score(X_test,y_test)\n",
    "    sum_score+=score_svm\n",
    "    \n",
    "print(sum_score/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae7579-bc36-4a34-964c-2ef0f88e83ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b1766-f2cf-43ca-91d6-0ab5b7d1ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5286f-40c1-419d-8903-38b65fb728de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf8ab5-b196-4370-acd4-e8a7701c911d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dae01-dae0-4658-ab99-95d6527b70d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67969741-8382-4a0c-8b3b-344677f27fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cfba5a6-a600-4fda-947b-9b7cc5efc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80890-a6e7-4991-9439-b03f2c071075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cacf574-8e1c-4bd8-80f1-686dc3ef102a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e07382d-aabd-43d4-b5f8-6123541097dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_95 = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3bd6285-a442-43e6-822f-43e5825dfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_95 = pca_95.fit_transform(features_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d66561e-5617-4bdc-98dc-e7701f255545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.56762642e+00, -6.14394036e+00, -5.87746840e+00, ...,\n",
       "         1.48027383e-01, -2.54059601e-04,  1.21772079e-02],\n",
       "       [ 1.35500472e+00,  4.56816082e+00, -5.34499327e+00, ...,\n",
       "        -2.14018458e-01, -4.71534827e-02,  6.15016398e-02],\n",
       "       [-2.35517192e-01,  6.64676388e-02, -5.72585132e+00, ...,\n",
       "         3.99579995e-01,  2.57755878e-02, -3.90237560e-01],\n",
       "       ...,\n",
       "       [ 4.76982831e+00, -1.69260261e+00, -5.51044536e+00, ...,\n",
       "         1.05367955e-01,  2.78847721e-01,  1.27193034e-01],\n",
       "       [ 1.80366950e+00, -2.88534891e+00, -5.80045433e+00, ...,\n",
       "        -3.47656913e-02,  5.76471002e-02,  4.82596304e-01],\n",
       "       [ 7.23584374e+00, -1.34154760e+00, -6.14632919e+00, ...,\n",
       "         2.37494542e-01,  2.65386724e-01, -7.73621059e-03]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c2bc5-5fb2-41a9-ba19-2de82366cea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28776ea0-6569-410e-a5cc-bc9dc87b9054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac620775-cc78-4ff6-a03c-f2f931185a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a635b32-6afe-4256-9e4f-5e3bd5e56b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 100)\n",
      "(117,)\n",
      "(21, 100)\n",
      "(21,)\n",
      "(99, 100)\n",
      "(99,)\n",
      "(18, 100)\n",
      "(18,)\n",
      "(21, 100)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "train_features_full, test_features, train_target_full, test_target = train_test_split(\n",
    "    features_95, target, \n",
    "    test_size = 0.15)\n",
    "print(train_features_full.shape)\n",
    "print(train_target_full.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)\n",
    "train_features, validation_features, train_target, validation_target = train_test_split(\n",
    "    train_features_full, train_target_full, \n",
    "    test_size = 0.15)\n",
    "print(train_features.shape)\n",
    "print(train_target.shape)\n",
    "print(validation_features.shape)\n",
    "print(validation_target.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed0733f1-deac-43b8-9214-57b66daced09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 19:02:51.349989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 19:02:52.696581: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "input_  = keras.layers.Input(shape = train_features.shape[1:])\n",
    "hidden1 = keras.layers.Dense(10,activation='selu')(input_)\n",
    "hidden2 = keras.layers.Dense(5,activation='selu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1,activation='sigmoid')(concat)\n",
    "model_wide = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9fcb61e-9927-40fe-8f61-e5d602adfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "020cebab-5868-4a3a-ada8-5e0acbd427e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 49ms/step - loss: 1.2849 - accuracy: 0.4949 - val_loss: 1.0158 - val_accuracy: 0.6111\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1806 - accuracy: 0.4949 - val_loss: 0.9690 - val_accuracy: 0.6111\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1055 - accuracy: 0.5051 - val_loss: 0.9361 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0451 - accuracy: 0.5152 - val_loss: 0.9067 - val_accuracy: 0.6667\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9868 - accuracy: 0.5051 - val_loss: 0.8817 - val_accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9338 - accuracy: 0.5152 - val_loss: 0.8577 - val_accuracy: 0.6111\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8844 - accuracy: 0.5152 - val_loss: 0.8352 - val_accuracy: 0.6111\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8339 - accuracy: 0.5354 - val_loss: 0.8119 - val_accuracy: 0.6111\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7914 - accuracy: 0.5556 - val_loss: 0.7934 - val_accuracy: 0.6111\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7495 - accuracy: 0.5556 - val_loss: 0.7749 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7097 - accuracy: 0.6061 - val_loss: 0.7585 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6736 - accuracy: 0.6162 - val_loss: 0.7430 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6381 - accuracy: 0.6364 - val_loss: 0.7282 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6080 - accuracy: 0.6566 - val_loss: 0.7139 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5807 - accuracy: 0.6667 - val_loss: 0.7005 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5575 - accuracy: 0.6768 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5368 - accuracy: 0.6970 - val_loss: 0.6786 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5209 - accuracy: 0.7172 - val_loss: 0.6693 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5059 - accuracy: 0.7374 - val_loss: 0.6606 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.7576 - val_loss: 0.6527 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4811 - accuracy: 0.7677 - val_loss: 0.6442 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.7677 - val_loss: 0.6365 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.6290 - val_accuracy: 0.5556\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.6194 - val_accuracy: 0.5556\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4352 - accuracy: 0.7980 - val_loss: 0.6102 - val_accuracy: 0.5556\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4241 - accuracy: 0.8182 - val_loss: 0.6020 - val_accuracy: 0.5556\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4145 - accuracy: 0.8182 - val_loss: 0.5941 - val_accuracy: 0.5556\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4056 - accuracy: 0.8384 - val_loss: 0.5876 - val_accuracy: 0.6111\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3953 - accuracy: 0.8485 - val_loss: 0.5797 - val_accuracy: 0.6111\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3852 - accuracy: 0.8788 - val_loss: 0.5710 - val_accuracy: 0.5556\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3774 - accuracy: 0.8788 - val_loss: 0.5628 - val_accuracy: 0.5556\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - accuracy: 0.8788 - val_loss: 0.5545 - val_accuracy: 0.5556\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3585 - accuracy: 0.8889 - val_loss: 0.5472 - val_accuracy: 0.5556\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3522 - accuracy: 0.8889 - val_loss: 0.5394 - val_accuracy: 0.5556\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3434 - accuracy: 0.8889 - val_loss: 0.5338 - val_accuracy: 0.6111\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 0.8889 - val_loss: 0.5287 - val_accuracy: 0.6111\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.8788 - val_loss: 0.5231 - val_accuracy: 0.6111\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3194 - accuracy: 0.8990 - val_loss: 0.5186 - val_accuracy: 0.6111\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3131 - accuracy: 0.8788 - val_loss: 0.5140 - val_accuracy: 0.6111\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3036 - accuracy: 0.9091 - val_loss: 0.5117 - val_accuracy: 0.6111\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2967 - accuracy: 0.9091 - val_loss: 0.5084 - val_accuracy: 0.6111\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2905 - accuracy: 0.8990 - val_loss: 0.5063 - val_accuracy: 0.6111\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2824 - accuracy: 0.8990 - val_loss: 0.5038 - val_accuracy: 0.6111\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2771 - accuracy: 0.8990 - val_loss: 0.5035 - val_accuracy: 0.6111\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2686 - accuracy: 0.8990 - val_loss: 0.5025 - val_accuracy: 0.6111\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.8990 - val_loss: 0.5025 - val_accuracy: 0.6111\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2565 - accuracy: 0.8990 - val_loss: 0.5001 - val_accuracy: 0.6111\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2499 - accuracy: 0.9091 - val_loss: 0.5005 - val_accuracy: 0.6111\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2436 - accuracy: 0.9091 - val_loss: 0.5017 - val_accuracy: 0.6111\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2376 - accuracy: 0.9091 - val_loss: 0.5014 - val_accuracy: 0.6111\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2331 - accuracy: 0.9091 - val_loss: 0.5031 - val_accuracy: 0.6111\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.9293 - val_loss: 0.5041 - val_accuracy: 0.6667\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2208 - accuracy: 0.9293 - val_loss: 0.5072 - val_accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2157 - accuracy: 0.9293 - val_loss: 0.5100 - val_accuracy: 0.6667\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2091 - accuracy: 0.9293 - val_loss: 0.5145 - val_accuracy: 0.6667\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2047 - accuracy: 0.9293 - val_loss: 0.5153 - val_accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1989 - accuracy: 0.9293 - val_loss: 0.5152 - val_accuracy: 0.6667\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1940 - accuracy: 0.9293 - val_loss: 0.5171 - val_accuracy: 0.6667\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1888 - accuracy: 0.9293 - val_loss: 0.5202 - val_accuracy: 0.6667\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 0.9596 - val_loss: 0.5238 - val_accuracy: 0.6667\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1798 - accuracy: 0.9394 - val_loss: 0.5255 - val_accuracy: 0.6667\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1746 - accuracy: 0.9495 - val_loss: 0.5285 - val_accuracy: 0.6667\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9495 - val_loss: 0.5323 - val_accuracy: 0.6667\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.9596 - val_loss: 0.5355 - val_accuracy: 0.6667\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1625 - accuracy: 0.9596 - val_loss: 0.5365 - val_accuracy: 0.6667\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9596 - val_loss: 0.5402 - val_accuracy: 0.6667\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1551 - accuracy: 0.9697 - val_loss: 0.5434 - val_accuracy: 0.6667\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1507 - accuracy: 0.9697 - val_loss: 0.5487 - val_accuracy: 0.6667\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1469 - accuracy: 0.9596 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1430 - accuracy: 0.9697 - val_loss: 0.5593 - val_accuracy: 0.7222\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.9697 - val_loss: 0.5628 - val_accuracy: 0.7222\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1369 - accuracy: 0.9697 - val_loss: 0.5680 - val_accuracy: 0.7222\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1330 - accuracy: 0.9697 - val_loss: 0.5724 - val_accuracy: 0.7222\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1291 - accuracy: 0.9697 - val_loss: 0.5767 - val_accuracy: 0.7222\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1263 - accuracy: 0.9798 - val_loss: 0.5853 - val_accuracy: 0.7222\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1228 - accuracy: 0.9697 - val_loss: 0.5893 - val_accuracy: 0.7222\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1199 - accuracy: 0.9798 - val_loss: 0.5949 - val_accuracy: 0.7222\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1169 - accuracy: 0.9798 - val_loss: 0.6018 - val_accuracy: 0.7222\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9798 - val_loss: 0.6052 - val_accuracy: 0.7222\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1104 - accuracy: 0.9798 - val_loss: 0.6115 - val_accuracy: 0.7222\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1075 - accuracy: 0.9798 - val_loss: 0.6138 - val_accuracy: 0.7222\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1049 - accuracy: 0.9798 - val_loss: 0.6207 - val_accuracy: 0.7222\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1016 - accuracy: 0.9798 - val_loss: 0.6294 - val_accuracy: 0.7222\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 0.9798 - val_loss: 0.6343 - val_accuracy: 0.7222\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0969 - accuracy: 0.9798 - val_loss: 0.6390 - val_accuracy: 0.7222\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9798 - val_loss: 0.6436 - val_accuracy: 0.7222\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9798 - val_loss: 0.6476 - val_accuracy: 0.7222\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.9798 - val_loss: 0.6554 - val_accuracy: 0.7222\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0858 - accuracy: 0.9798 - val_loss: 0.6591 - val_accuracy: 0.7222\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9798 - val_loss: 0.6618 - val_accuracy: 0.7222\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0807 - accuracy: 0.9899 - val_loss: 0.6713 - val_accuracy: 0.7222\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0779 - accuracy: 0.9899 - val_loss: 0.6808 - val_accuracy: 0.7222\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0759 - accuracy: 0.9899 - val_loss: 0.6875 - val_accuracy: 0.7222\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0745 - accuracy: 0.9798 - val_loss: 0.6967 - val_accuracy: 0.7222\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9899 - val_loss: 0.7026 - val_accuracy: 0.7222\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9899 - val_loss: 0.7100 - val_accuracy: 0.7222\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9899 - val_loss: 0.7187 - val_accuracy: 0.7222\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9899 - val_loss: 0.7269 - val_accuracy: 0.7222\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9899 - val_loss: 0.7371 - val_accuracy: 0.7222\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9899 - val_loss: 0.7456 - val_accuracy: 0.7222\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9899 - val_loss: 0.7566 - val_accuracy: 0.7222\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9899 - val_loss: 0.7688 - val_accuracy: 0.7222\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9899 - val_loss: 0.7778 - val_accuracy: 0.7222\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 0.9899 - val_loss: 0.7867 - val_accuracy: 0.7222\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7222\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7222\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0494 - accuracy: 0.9899 - val_loss: 0.8179 - val_accuracy: 0.7222\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.8306 - val_accuracy: 0.7222\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.8428 - val_accuracy: 0.7222\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.7222\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.7222\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7222\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.7222\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.8959 - val_accuracy: 0.7222\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.7222\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.9240 - val_accuracy: 0.7222\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.7222\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.9437 - val_accuracy: 0.7222\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.7222\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.7222\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.7222\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.7222\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.7222\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.7222\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7222\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.7222\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.7222\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.7222\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.7222\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.7778\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.7778\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.7778\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.1459 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.7778\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.7778\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.7778\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.2044 - val_accuracy: 0.7778\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.2362 - val_accuracy: 0.7778\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7778\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.2676 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.7778\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.2997 - val_accuracy: 0.7778\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.7778\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.3595 - val_accuracy: 0.7778\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3816 - val_accuracy: 0.7778\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.3854 - val_accuracy: 0.7778\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4047 - val_accuracy: 0.7778\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4284 - val_accuracy: 0.7778\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.7778\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.7778\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4899 - val_accuracy: 0.7778\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.7778\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5250 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.7778\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5480 - val_accuracy: 0.7778\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.7778\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.7778\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6203 - val_accuracy: 0.7778\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6304 - val_accuracy: 0.7778\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6503 - val_accuracy: 0.7778\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.7778\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6902 - val_accuracy: 0.7778\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7077 - val_accuracy: 0.7778\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7215 - val_accuracy: 0.7778\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.7778\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7750 - val_accuracy: 0.7778\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7881 - val_accuracy: 0.7778\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.7778\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8348 - val_accuracy: 0.7778\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8590 - val_accuracy: 0.7778\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.7778\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8972 - val_accuracy: 0.7778\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9210 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9312 - val_accuracy: 0.7778\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9576 - val_accuracy: 0.7778\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9761 - val_accuracy: 0.7778\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9917 - val_accuracy: 0.7778\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0061 - val_accuracy: 0.7778\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0225 - val_accuracy: 0.7778\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 9.9105e-04 - accuracy: 1.0000 - val_loss: 2.0502 - val_accuracy: 0.7778\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.2953e-04 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.7778\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7997e-04 - accuracy: 1.0000 - val_loss: 2.0869 - val_accuracy: 0.7778\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.4517e-04 - accuracy: 1.0000 - val_loss: 2.1007 - val_accuracy: 0.7778\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7.9869e-04 - accuracy: 1.0000 - val_loss: 2.1183 - val_accuracy: 0.7778\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3874e-04 - accuracy: 1.0000 - val_loss: 2.1363 - val_accuracy: 0.7778\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.9511e-04 - accuracy: 1.0000 - val_loss: 2.1596 - val_accuracy: 0.7778\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6.8251e-04 - accuracy: 1.0000 - val_loss: 2.1841 - val_accuracy: 0.7778\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6.2307e-04 - accuracy: 1.0000 - val_loss: 2.1986 - val_accuracy: 0.7778\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.9984e-04 - accuracy: 1.0000 - val_loss: 2.2208 - val_accuracy: 0.7778\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5.7017e-04 - accuracy: 1.0000 - val_loss: 2.2273 - val_accuracy: 0.7778\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.3134e-04 - accuracy: 1.0000 - val_loss: 2.2484 - val_accuracy: 0.7778\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.0581e-04 - accuracy: 1.0000 - val_loss: 2.2559 - val_accuracy: 0.7778\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.8710e-04 - accuracy: 1.0000 - val_loss: 2.2751 - val_accuracy: 0.7778\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5119e-04 - accuracy: 1.0000 - val_loss: 2.2965 - val_accuracy: 0.7778\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.4123e-04 - accuracy: 1.0000 - val_loss: 2.3089 - val_accuracy: 0.7778\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.2012e-04 - accuracy: 1.0000 - val_loss: 2.3266 - val_accuracy: 0.7778\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.9338e-04 - accuracy: 1.0000 - val_loss: 2.3450 - val_accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.7170e-04 - accuracy: 1.0000 - val_loss: 2.3583 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe39b82cb90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wide.fit(train_features, train_target, batch_size = 20, epochs=200,\n",
    "         validation_data=(validation_features, validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b816f19f-dc90-4b68-9dca-1070144a17e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_len = features_95.shape[1]\n",
    "\n",
    "features_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a64eedf-11b9-4b52-aed1-c5ec9f0c8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.71118055e-01, -3.59808605e-01, -1.94592764e+00, ...,\n",
       "        -2.78010049e-02,  3.86765089e-02, -1.95710097e-02],\n",
       "       [-1.87473156e+00,  6.83776835e-01,  8.40076486e-01, ...,\n",
       "        -3.47656913e-02,  5.76471002e-02,  4.82596304e-01],\n",
       "       [ 1.49463469e-01, -3.21355530e-02,  3.70996538e-02, ...,\n",
       "        -1.46259247e-01, -3.11010699e-01,  1.43902610e-02],\n",
       "       ...,\n",
       "       [ 2.30711147e-01, -1.50799934e-01, -8.11202366e-01, ...,\n",
       "        -4.02798288e-02,  2.66977944e-02, -5.03046846e-03],\n",
       "       [-1.74700197e+00, -1.05729890e+00,  5.78545904e-01, ...,\n",
       "        -1.55054676e-02, -2.48159928e-02,  8.69302432e-02],\n",
       "       [-3.03925116e-01,  7.09033597e-02,  6.54317020e-01, ...,\n",
       "         1.11413243e-01,  9.35795173e-03, -6.40036034e-04]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_A = train_features[:,:features_len//3]\n",
    "train_features_B = train_features[:,features_len//3:]\n",
    "\n",
    "validation_features_A = validation_features[:,:features_len//3]\n",
    "validation_features_B = validation_features[:,features_len//3:]\n",
    "train_features_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4a1a15b-a300-46b1-9aa0-112c8c9818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[features_len//3], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[features_len-features_len//3], name=\"deep_input\")\n",
    "hidden1_ = keras.layers.Dense(5, activation=\"selu\")(input_B)\n",
    "hidden2_ = keras.layers.Dense(3, activation=\"selu\")(hidden1_)\n",
    "concat_ = keras.layers.concatenate([input_A, hidden2_])\n",
    "output_ = keras.layers.Dense(1,activation='sigmoid')(concat_)\n",
    "model_combine = keras.Model(inputs=[input_A, input_B], outputs=[output_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42101c49-463c-474c-923c-9737282d05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3b13151-b014-40b9-937f-0a9d283ab387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 1s 40ms/step - loss: 1.1382 - accuracy: 0.6364 - val_loss: 1.3865 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1059 - accuracy: 0.6263 - val_loss: 1.3705 - val_accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0836 - accuracy: 0.6364 - val_loss: 1.3560 - val_accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0628 - accuracy: 0.6364 - val_loss: 1.3415 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0464 - accuracy: 0.6162 - val_loss: 1.3292 - val_accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0277 - accuracy: 0.6162 - val_loss: 1.3159 - val_accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0123 - accuracy: 0.6162 - val_loss: 1.3031 - val_accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9951 - accuracy: 0.6061 - val_loss: 1.2903 - val_accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9798 - accuracy: 0.6061 - val_loss: 1.2767 - val_accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9648 - accuracy: 0.5960 - val_loss: 1.2645 - val_accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9492 - accuracy: 0.6162 - val_loss: 1.2519 - val_accuracy: 0.5000\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9342 - accuracy: 0.6364 - val_loss: 1.2405 - val_accuracy: 0.5000\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9186 - accuracy: 0.6263 - val_loss: 1.2294 - val_accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9056 - accuracy: 0.6263 - val_loss: 1.2194 - val_accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8908 - accuracy: 0.6263 - val_loss: 1.2094 - val_accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8769 - accuracy: 0.6465 - val_loss: 1.1993 - val_accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8630 - accuracy: 0.6364 - val_loss: 1.1890 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8505 - accuracy: 0.6364 - val_loss: 1.1787 - val_accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8362 - accuracy: 0.6364 - val_loss: 1.1686 - val_accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8225 - accuracy: 0.6465 - val_loss: 1.1577 - val_accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8094 - accuracy: 0.6465 - val_loss: 1.1475 - val_accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7975 - accuracy: 0.6566 - val_loss: 1.1367 - val_accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7846 - accuracy: 0.6667 - val_loss: 1.1277 - val_accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7730 - accuracy: 0.6768 - val_loss: 1.1176 - val_accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7602 - accuracy: 0.6768 - val_loss: 1.1091 - val_accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7489 - accuracy: 0.6970 - val_loss: 1.1004 - val_accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7372 - accuracy: 0.6970 - val_loss: 1.0921 - val_accuracy: 0.5000\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7253 - accuracy: 0.6970 - val_loss: 1.0830 - val_accuracy: 0.5000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7142 - accuracy: 0.6869 - val_loss: 1.0744 - val_accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7023 - accuracy: 0.7071 - val_loss: 1.0661 - val_accuracy: 0.5556\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.6970 - val_loss: 1.0598 - val_accuracy: 0.5556\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.7172 - val_loss: 1.0530 - val_accuracy: 0.5556\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6688 - accuracy: 0.7172 - val_loss: 1.0462 - val_accuracy: 0.5556\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6585 - accuracy: 0.7172 - val_loss: 1.0394 - val_accuracy: 0.5556\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6468 - accuracy: 0.7172 - val_loss: 1.0320 - val_accuracy: 0.5556\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6356 - accuracy: 0.7172 - val_loss: 1.0261 - val_accuracy: 0.5556\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.7172 - val_loss: 1.0200 - val_accuracy: 0.5556\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.7172 - val_loss: 1.0141 - val_accuracy: 0.5556\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6037 - accuracy: 0.7172 - val_loss: 1.0083 - val_accuracy: 0.5556\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5937 - accuracy: 0.7071 - val_loss: 1.0034 - val_accuracy: 0.5556\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5835 - accuracy: 0.7071 - val_loss: 0.9987 - val_accuracy: 0.5556\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5746 - accuracy: 0.7071 - val_loss: 0.9949 - val_accuracy: 0.5556\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5648 - accuracy: 0.7273 - val_loss: 0.9910 - val_accuracy: 0.5556\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5552 - accuracy: 0.7374 - val_loss: 0.9871 - val_accuracy: 0.5556\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5461 - accuracy: 0.7374 - val_loss: 0.9836 - val_accuracy: 0.5556\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5363 - accuracy: 0.7475 - val_loss: 0.9803 - val_accuracy: 0.5556\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5270 - accuracy: 0.7576 - val_loss: 0.9766 - val_accuracy: 0.5556\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5181 - accuracy: 0.7576 - val_loss: 0.9743 - val_accuracy: 0.5556\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5097 - accuracy: 0.7576 - val_loss: 0.9717 - val_accuracy: 0.5556\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5004 - accuracy: 0.7576 - val_loss: 0.9696 - val_accuracy: 0.5556\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4911 - accuracy: 0.7677 - val_loss: 0.9677 - val_accuracy: 0.5556\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.7677 - val_loss: 0.9658 - val_accuracy: 0.5556\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.7879 - val_loss: 0.9643 - val_accuracy: 0.5556\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4647 - accuracy: 0.7879 - val_loss: 0.9624 - val_accuracy: 0.5556\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4567 - accuracy: 0.7879 - val_loss: 0.9600 - val_accuracy: 0.5556\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4483 - accuracy: 0.7879 - val_loss: 0.9593 - val_accuracy: 0.5556\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4392 - accuracy: 0.7879 - val_loss: 0.9574 - val_accuracy: 0.5556\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.7980 - val_loss: 0.9557 - val_accuracy: 0.5556\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.7879 - val_loss: 0.9532 - val_accuracy: 0.5556\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4158 - accuracy: 0.7980 - val_loss: 0.9520 - val_accuracy: 0.5556\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4076 - accuracy: 0.7980 - val_loss: 0.9512 - val_accuracy: 0.5556\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4014 - accuracy: 0.7980 - val_loss: 0.9511 - val_accuracy: 0.5556\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3929 - accuracy: 0.7980 - val_loss: 0.9513 - val_accuracy: 0.5556\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.8182 - val_loss: 0.9517 - val_accuracy: 0.5556\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3788 - accuracy: 0.8283 - val_loss: 0.9526 - val_accuracy: 0.5556\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3723 - accuracy: 0.8283 - val_loss: 0.9536 - val_accuracy: 0.5556\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3651 - accuracy: 0.8384 - val_loss: 0.9552 - val_accuracy: 0.5556\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3594 - accuracy: 0.8283 - val_loss: 0.9573 - val_accuracy: 0.5556\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3530 - accuracy: 0.8485 - val_loss: 0.9579 - val_accuracy: 0.5556\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.8586 - val_loss: 0.9593 - val_accuracy: 0.5556\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3402 - accuracy: 0.8687 - val_loss: 0.9616 - val_accuracy: 0.5556\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3345 - accuracy: 0.8788 - val_loss: 0.9631 - val_accuracy: 0.5556\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8889 - val_loss: 0.9637 - val_accuracy: 0.5556\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3230 - accuracy: 0.8889 - val_loss: 0.9666 - val_accuracy: 0.5556\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3173 - accuracy: 0.9091 - val_loss: 0.9674 - val_accuracy: 0.5556\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3120 - accuracy: 0.9091 - val_loss: 0.9673 - val_accuracy: 0.5556\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3068 - accuracy: 0.9091 - val_loss: 0.9690 - val_accuracy: 0.5556\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.9192 - val_loss: 0.9698 - val_accuracy: 0.5556\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2970 - accuracy: 0.9091 - val_loss: 0.9701 - val_accuracy: 0.5556\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2914 - accuracy: 0.9293 - val_loss: 0.9713 - val_accuracy: 0.5556\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2865 - accuracy: 0.9293 - val_loss: 0.9726 - val_accuracy: 0.5556\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2820 - accuracy: 0.9293 - val_loss: 0.9742 - val_accuracy: 0.5556\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2774 - accuracy: 0.9293 - val_loss: 0.9763 - val_accuracy: 0.5556\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2731 - accuracy: 0.9293 - val_loss: 0.9784 - val_accuracy: 0.5556\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2682 - accuracy: 0.9293 - val_loss: 0.9803 - val_accuracy: 0.5556\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2640 - accuracy: 0.9293 - val_loss: 0.9824 - val_accuracy: 0.5556\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2602 - accuracy: 0.9293 - val_loss: 0.9838 - val_accuracy: 0.5556\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2553 - accuracy: 0.9293 - val_loss: 0.9864 - val_accuracy: 0.5000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2519 - accuracy: 0.9394 - val_loss: 0.9894 - val_accuracy: 0.5000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2476 - accuracy: 0.9394 - val_loss: 0.9913 - val_accuracy: 0.5000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2444 - accuracy: 0.9394 - val_loss: 0.9927 - val_accuracy: 0.5000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9394 - val_loss: 0.9950 - val_accuracy: 0.5000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2361 - accuracy: 0.9596 - val_loss: 0.9969 - val_accuracy: 0.5000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 0.9596 - val_loss: 0.9986 - val_accuracy: 0.5000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2283 - accuracy: 0.9596 - val_loss: 1.0009 - val_accuracy: 0.5000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2257 - accuracy: 0.9596 - val_loss: 1.0040 - val_accuracy: 0.5000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2215 - accuracy: 0.9596 - val_loss: 1.0056 - val_accuracy: 0.5000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2182 - accuracy: 0.9596 - val_loss: 1.0078 - val_accuracy: 0.5556\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2150 - accuracy: 0.9596 - val_loss: 1.0109 - val_accuracy: 0.5556\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9596 - val_loss: 1.0118 - val_accuracy: 0.5556\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2096 - accuracy: 0.9596 - val_loss: 1.0145 - val_accuracy: 0.5556\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2064 - accuracy: 0.9596 - val_loss: 1.0173 - val_accuracy: 0.5556\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2038 - accuracy: 0.9596 - val_loss: 1.0200 - val_accuracy: 0.6111\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2012 - accuracy: 0.9596 - val_loss: 1.0222 - val_accuracy: 0.6111\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1984 - accuracy: 0.9697 - val_loss: 1.0261 - val_accuracy: 0.6111\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1955 - accuracy: 0.9697 - val_loss: 1.0292 - val_accuracy: 0.6111\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1932 - accuracy: 0.9697 - val_loss: 1.0326 - val_accuracy: 0.6111\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1904 - accuracy: 0.9697 - val_loss: 1.0358 - val_accuracy: 0.6111\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 0.9697 - val_loss: 1.0382 - val_accuracy: 0.6111\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1854 - accuracy: 0.9697 - val_loss: 1.0395 - val_accuracy: 0.6111\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1829 - accuracy: 0.9697 - val_loss: 1.0422 - val_accuracy: 0.6111\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1810 - accuracy: 0.9697 - val_loss: 1.0449 - val_accuracy: 0.6111\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1778 - accuracy: 0.9697 - val_loss: 1.0472 - val_accuracy: 0.6111\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.9697 - val_loss: 1.0499 - val_accuracy: 0.6111\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1738 - accuracy: 0.9697 - val_loss: 1.0524 - val_accuracy: 0.6111\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1714 - accuracy: 0.9697 - val_loss: 1.0546 - val_accuracy: 0.6111\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1694 - accuracy: 0.9697 - val_loss: 1.0565 - val_accuracy: 0.6111\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1673 - accuracy: 0.9697 - val_loss: 1.0591 - val_accuracy: 0.6111\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1650 - accuracy: 0.9697 - val_loss: 1.0623 - val_accuracy: 0.6111\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1630 - accuracy: 0.9697 - val_loss: 1.0661 - val_accuracy: 0.6111\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1606 - accuracy: 0.9697 - val_loss: 1.0696 - val_accuracy: 0.6111\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1584 - accuracy: 0.9697 - val_loss: 1.0716 - val_accuracy: 0.6111\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1568 - accuracy: 0.9697 - val_loss: 1.0747 - val_accuracy: 0.6111\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1548 - accuracy: 0.9697 - val_loss: 1.0774 - val_accuracy: 0.6111\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1527 - accuracy: 0.9697 - val_loss: 1.0811 - val_accuracy: 0.6111\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1503 - accuracy: 0.9697 - val_loss: 1.0847 - val_accuracy: 0.6111\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1482 - accuracy: 0.9697 - val_loss: 1.0888 - val_accuracy: 0.6111\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1469 - accuracy: 0.9697 - val_loss: 1.0947 - val_accuracy: 0.6111\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1451 - accuracy: 0.9798 - val_loss: 1.0966 - val_accuracy: 0.6111\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1425 - accuracy: 0.9798 - val_loss: 1.1010 - val_accuracy: 0.5556\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1407 - accuracy: 0.9798 - val_loss: 1.1060 - val_accuracy: 0.5556\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1390 - accuracy: 0.9798 - val_loss: 1.1109 - val_accuracy: 0.5556\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1367 - accuracy: 0.9798 - val_loss: 1.1155 - val_accuracy: 0.5556\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9798 - val_loss: 1.1209 - val_accuracy: 0.6111\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1326 - accuracy: 0.9798 - val_loss: 1.1260 - val_accuracy: 0.6111\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1309 - accuracy: 0.9798 - val_loss: 1.1318 - val_accuracy: 0.6111\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9798 - val_loss: 1.1368 - val_accuracy: 0.6111\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1267 - accuracy: 0.9798 - val_loss: 1.1420 - val_accuracy: 0.6111\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1245 - accuracy: 0.9798 - val_loss: 1.1463 - val_accuracy: 0.6111\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.9798 - val_loss: 1.1515 - val_accuracy: 0.6111\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1208 - accuracy: 0.9798 - val_loss: 1.1560 - val_accuracy: 0.6111\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1183 - accuracy: 0.9798 - val_loss: 1.1612 - val_accuracy: 0.6111\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1166 - accuracy: 0.9798 - val_loss: 1.1690 - val_accuracy: 0.6111\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1138 - accuracy: 0.9798 - val_loss: 1.1761 - val_accuracy: 0.6111\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1119 - accuracy: 0.9798 - val_loss: 1.1831 - val_accuracy: 0.6111\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1100 - accuracy: 0.9798 - val_loss: 1.1892 - val_accuracy: 0.5556\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1076 - accuracy: 0.9798 - val_loss: 1.1957 - val_accuracy: 0.5556\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 0.9798 - val_loss: 1.2008 - val_accuracy: 0.6111\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1038 - accuracy: 0.9798 - val_loss: 1.2048 - val_accuracy: 0.6111\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9899 - val_loss: 1.2108 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe37c30cb90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combine.fit([train_features_A, train_features_B],train_target,batch_size = 20, epochs=150,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcebb4f3-364e-4e5c-9d4e-4fa6ee8e84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir='output/logs',histogram_freq=1,embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c24aeda-2931-4659-bf35-53309398fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1012 - accuracy: 0.9899 - val_loss: 1.2151 - val_accuracy: 0.6111\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0994 - accuracy: 0.9899 - val_loss: 1.2206 - val_accuracy: 0.6111\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0977 - accuracy: 0.9899 - val_loss: 1.2260 - val_accuracy: 0.6111\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0965 - accuracy: 0.9899 - val_loss: 1.2324 - val_accuracy: 0.6111\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0950 - accuracy: 0.9899 - val_loss: 1.2380 - val_accuracy: 0.6111\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0934 - accuracy: 0.9899 - val_loss: 1.2448 - val_accuracy: 0.6111\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0920 - accuracy: 0.9899 - val_loss: 1.2520 - val_accuracy: 0.6111\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0907 - accuracy: 0.9899 - val_loss: 1.2560 - val_accuracy: 0.6111\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0888 - accuracy: 0.9899 - val_loss: 1.2596 - val_accuracy: 0.6111\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0875 - accuracy: 0.9899 - val_loss: 1.2656 - val_accuracy: 0.6111\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0862 - accuracy: 0.9899 - val_loss: 1.2722 - val_accuracy: 0.6111\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0849 - accuracy: 0.9899 - val_loss: 1.2774 - val_accuracy: 0.6111\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0839 - accuracy: 0.9899 - val_loss: 1.2834 - val_accuracy: 0.6111\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0823 - accuracy: 0.9899 - val_loss: 1.2865 - val_accuracy: 0.6111\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0810 - accuracy: 0.9899 - val_loss: 1.2935 - val_accuracy: 0.6111\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0796 - accuracy: 0.9899 - val_loss: 1.2980 - val_accuracy: 0.6111\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0786 - accuracy: 0.9899 - val_loss: 1.3038 - val_accuracy: 0.6111\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0773 - accuracy: 0.9899 - val_loss: 1.3112 - val_accuracy: 0.6111\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0762 - accuracy: 0.9899 - val_loss: 1.3183 - val_accuracy: 0.6111\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0751 - accuracy: 0.9899 - val_loss: 1.3230 - val_accuracy: 0.6111\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0741 - accuracy: 0.9899 - val_loss: 1.3322 - val_accuracy: 0.6111\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0726 - accuracy: 0.9899 - val_loss: 1.3388 - val_accuracy: 0.6111\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0714 - accuracy: 0.9899 - val_loss: 1.3469 - val_accuracy: 0.6111\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0708 - accuracy: 0.9899 - val_loss: 1.3548 - val_accuracy: 0.6111\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0694 - accuracy: 0.9899 - val_loss: 1.3617 - val_accuracy: 0.6111\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0683 - accuracy: 0.9899 - val_loss: 1.3705 - val_accuracy: 0.6111\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0674 - accuracy: 0.9899 - val_loss: 1.3782 - val_accuracy: 0.6111\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0662 - accuracy: 0.9899 - val_loss: 1.3876 - val_accuracy: 0.6111\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0651 - accuracy: 0.9899 - val_loss: 1.3954 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0638 - accuracy: 0.9899 - val_loss: 1.4041 - val_accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0630 - accuracy: 0.9899 - val_loss: 1.4126 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0621 - accuracy: 0.9899 - val_loss: 1.4199 - val_accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0608 - accuracy: 0.9899 - val_loss: 1.4278 - val_accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0599 - accuracy: 0.9899 - val_loss: 1.4360 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0588 - accuracy: 0.9899 - val_loss: 1.4444 - val_accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0581 - accuracy: 0.9899 - val_loss: 1.4536 - val_accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0572 - accuracy: 0.9899 - val_loss: 1.4633 - val_accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0563 - accuracy: 0.9899 - val_loss: 1.4714 - val_accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0551 - accuracy: 0.9899 - val_loss: 1.4810 - val_accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0543 - accuracy: 0.9899 - val_loss: 1.4901 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0534 - accuracy: 0.9899 - val_loss: 1.4993 - val_accuracy: 0.7222\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0525 - accuracy: 0.9899 - val_loss: 1.5050 - val_accuracy: 0.7222\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0517 - accuracy: 0.9899 - val_loss: 1.5123 - val_accuracy: 0.7222\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0509 - accuracy: 0.9899 - val_loss: 1.5233 - val_accuracy: 0.7222\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0500 - accuracy: 0.9899 - val_loss: 1.5327 - val_accuracy: 0.7222\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0492 - accuracy: 0.9899 - val_loss: 1.5419 - val_accuracy: 0.7222\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0483 - accuracy: 0.9899 - val_loss: 1.5539 - val_accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0475 - accuracy: 0.9899 - val_loss: 1.5648 - val_accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0464 - accuracy: 0.9899 - val_loss: 1.5770 - val_accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0460 - accuracy: 0.9899 - val_loss: 1.5882 - val_accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0451 - accuracy: 0.9899 - val_loss: 1.5992 - val_accuracy: 0.6111\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 1.6106 - val_accuracy: 0.6111\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.6230 - val_accuracy: 0.6111\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.6361 - val_accuracy: 0.6111\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.6111\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.6605 - val_accuracy: 0.6111\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 1.6743 - val_accuracy: 0.6111\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.6111\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.6111\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 1.7177 - val_accuracy: 0.6111\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.6111\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.7495 - val_accuracy: 0.5556\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.7640 - val_accuracy: 0.5556\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.7797 - val_accuracy: 0.5556\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.7965 - val_accuracy: 0.5556\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.8122 - val_accuracy: 0.5556\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 0.5556\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.8446 - val_accuracy: 0.5556\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 1.8602 - val_accuracy: 0.5556\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.8784 - val_accuracy: 0.5556\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.8985 - val_accuracy: 0.5556\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.9173 - val_accuracy: 0.5556\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.9364 - val_accuracy: 0.5556\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.9549 - val_accuracy: 0.5556\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.9757 - val_accuracy: 0.5556\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.9950 - val_accuracy: 0.5556\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 2.0136 - val_accuracy: 0.5556\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.0313 - val_accuracy: 0.5556\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.0486 - val_accuracy: 0.5556\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.5556\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.0901 - val_accuracy: 0.5556\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.1105 - val_accuracy: 0.5556\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.1299 - val_accuracy: 0.5556\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.5556\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.1674 - val_accuracy: 0.5556\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.1878 - val_accuracy: 0.5556\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.2065 - val_accuracy: 0.5556\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.5556\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.2470 - val_accuracy: 0.5556\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.2683 - val_accuracy: 0.5556\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.2877 - val_accuracy: 0.5556\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.3059 - val_accuracy: 0.5556\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.3249 - val_accuracy: 0.5556\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.3481 - val_accuracy: 0.5556\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.3684 - val_accuracy: 0.5556\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.3888 - val_accuracy: 0.5556\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4086 - val_accuracy: 0.5556\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.4303 - val_accuracy: 0.5556\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.4485 - val_accuracy: 0.5556\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.4683 - val_accuracy: 0.5556\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.4866 - val_accuracy: 0.5556\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.5111 - val_accuracy: 0.5556\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.5314 - val_accuracy: 0.5556\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.5505 - val_accuracy: 0.5556\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.5733 - val_accuracy: 0.5556\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.5917 - val_accuracy: 0.5556\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.6159 - val_accuracy: 0.5556\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.6380 - val_accuracy: 0.5556\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.6601 - val_accuracy: 0.5556\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.6787 - val_accuracy: 0.5556\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.7004 - val_accuracy: 0.5556\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.5556\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.7423 - val_accuracy: 0.5556\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.5556\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.5556\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.7992 - val_accuracy: 0.5556\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.8253 - val_accuracy: 0.5556\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.8484 - val_accuracy: 0.5556\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.8668 - val_accuracy: 0.5556\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8910 - val_accuracy: 0.5556\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9120 - val_accuracy: 0.5556\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.5556\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9557 - val_accuracy: 0.5556\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.9779 - val_accuracy: 0.5556\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9983 - val_accuracy: 0.5556\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0178 - val_accuracy: 0.5556\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0399 - val_accuracy: 0.5556\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.0623 - val_accuracy: 0.5556\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0821 - val_accuracy: 0.5556\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.1043 - val_accuracy: 0.5556\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.1302 - val_accuracy: 0.5556\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.1504 - val_accuracy: 0.5556\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.5556\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1951 - val_accuracy: 0.5556\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.2163 - val_accuracy: 0.5556\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.2415 - val_accuracy: 0.5556\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.2597 - val_accuracy: 0.5556\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.2822 - val_accuracy: 0.5556\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.3070 - val_accuracy: 0.5556\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.3328 - val_accuracy: 0.5556\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.3582 - val_accuracy: 0.5556\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.3838 - val_accuracy: 0.5556\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.4090 - val_accuracy: 0.5556\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.4322 - val_accuracy: 0.5556\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.4518 - val_accuracy: 0.5556\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.4752 - val_accuracy: 0.5556\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.5020 - val_accuracy: 0.5556\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.5298 - val_accuracy: 0.5556\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.5549 - val_accuracy: 0.5556\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.5817 - val_accuracy: 0.5556\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.6089 - val_accuracy: 0.5556\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.6313 - val_accuracy: 0.5556\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.6551 - val_accuracy: 0.5556\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.6791 - val_accuracy: 0.5556\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.6983 - val_accuracy: 0.5556\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.7243 - val_accuracy: 0.5556\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.7470 - val_accuracy: 0.5556\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.7740 - val_accuracy: 0.5556\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.7958 - val_accuracy: 0.5556\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.8187 - val_accuracy: 0.5556\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.8402 - val_accuracy: 0.5556\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.8674 - val_accuracy: 0.5556\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.8972 - val_accuracy: 0.5556\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.9170 - val_accuracy: 0.5556\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.9395 - val_accuracy: 0.5556\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9636 - val_accuracy: 0.5556\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9891 - val_accuracy: 0.5556\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.0149 - val_accuracy: 0.5556\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.0404 - val_accuracy: 0.5556\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.0606 - val_accuracy: 0.5556\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0774 - val_accuracy: 0.5556\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0997 - val_accuracy: 0.5556\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1273 - val_accuracy: 0.5556\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1544 - val_accuracy: 0.5556\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1750 - val_accuracy: 0.5556\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1967 - val_accuracy: 0.5556\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.2131 - val_accuracy: 0.5556\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2375 - val_accuracy: 0.5556\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2621 - val_accuracy: 0.5556\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2851 - val_accuracy: 0.5556\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3032 - val_accuracy: 0.5556\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3220 - val_accuracy: 0.5556\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.3454 - val_accuracy: 0.5556\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.3691 - val_accuracy: 0.5556\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.3851 - val_accuracy: 0.5556\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4046 - val_accuracy: 0.5556\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4289 - val_accuracy: 0.5556\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4502 - val_accuracy: 0.5556\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4742 - val_accuracy: 0.5556\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4934 - val_accuracy: 0.5556\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.5124 - val_accuracy: 0.5556\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.5341 - val_accuracy: 0.5556\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.5562 - val_accuracy: 0.5556\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.5749 - val_accuracy: 0.5556\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.5971 - val_accuracy: 0.5556\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.6159 - val_accuracy: 0.5556\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.6404 - val_accuracy: 0.5556\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.6612 - val_accuracy: 0.5556\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9816e-04 - accuracy: 1.0000 - val_loss: 4.6827 - val_accuracy: 0.5556\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7085e-04 - accuracy: 1.0000 - val_loss: 4.7066 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe37c1f2510>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combine.fit((train_features_A, train_features_B),train_target,batch_size = 20, epochs=200,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target),\n",
    "                  callbacks=tensorboard_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d88ad5-9d7f-4e28-ae0c-fef1842c7b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0451e8-47f4-433b-b003-2799ee796a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0b045-47a7-49cb-b449-821f36e29925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1fca7e-dd22-4c1a-a602-5bfe23513340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
