{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from scipy.stats import ttest_ind, levene\n",
    "from tensorflow import keras\n",
    "\n",
    "data_LA = pd.read_csv(\"input/LA_total.csv\",index_col=0)\n",
    "data_XA = pd.read_csv(\"input/XA_total.csv\",index_col=0)\n",
    "\n",
    "\n",
    "data_LA_ = pd.DataFrame()\n",
    "columns_LA = data_LA.columns\n",
    "for col in columns_LA:\n",
    "    try:\n",
    "        df = data_LA[col].astype(np.float64)\n",
    "        data_LA_ = pd.concat([data_LA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "    \n",
    "data_XA_ = pd.DataFrame()\n",
    "columns_XA = data_XA.columns\n",
    "for col in columns_XA:\n",
    "    try:\n",
    "        df = data_XA[col].astype(np.float64)\n",
    "        data_XA_ = pd.concat([data_XA_,df],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    continue\n",
    "\n",
    "\n",
    "# 方差齐性\n",
    "index_ = []\n",
    "for col in data_LA_.columns:\n",
    "    if levene(data_LA_[col],data_XA_[col])[1] > 0.05:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col])[1] < 0.05:\n",
    "            index_.append(col)\n",
    "    else:\n",
    "        if ttest_ind(data_LA_[col],data_XA_[col],equal_var=False)[1] < 0.05:\n",
    "            index_.append(col)\n",
    "\n",
    "\n",
    "data_L_T = data_LA_[index_]\n",
    "data_X_T = data_XA_[index_]\n",
    "\n",
    "\n",
    "data = pd.concat([data_L_T,data_X_T])\n",
    "data = shuffle(data)\n",
    "\n",
    "target = data.iloc[:, 0]\n",
    "features = data.iloc[:,1:]\n",
    "features_bk = features.copy()\n",
    "\n",
    "transfer = StandardScaler()\n",
    "features_SS = transfer.fit_transform(features_bk)\n",
    "# 数据标准化很有必要\n",
    "\n",
    "alphas_ = np.logspace(-2,0,300)\n",
    "\n",
    "\n",
    "lassocv = LassoCV(alphas = alphas_,cv = 10,max_iter = 100000).fit(features_SS,target)\n",
    "lassocv.alpha_\n",
    "features = data[features.columns[lassocv.coef_!=0]]\n",
    "features_len = len(features.columns)\n",
    "print(features_len)\n",
    "# print(lassocv.coef_[lassocv.coef_!=0])\n",
    "features_SS =features_SS[:, pd.DataFrame(features_SS).columns[lassocv.coef_!=0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_full, test_features, train_target_full, test_target = train_test_split(\n",
    "    features_SS, target, \n",
    "    test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features_full.shape)\n",
    "print(train_target_full.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, validation_features, train_target, validation_target = train_test_split(\n",
    "    train_features_full, train_target_full, \n",
    "    test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(train_target.shape)\n",
    "print(validation_features.shape)\n",
    "print(validation_target.shape)\n",
    "print(test_features.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、建立模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wide 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_  = keras.layers.Input(shape = train_features.shape[1:])\n",
    "hidden1 = keras.layers.Dense(10,activation='selu')(input_)\n",
    "hidden2 = keras.layers.Dense(5,activation='selu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1,activation='sigmoid')(concat)\n",
    "model_wide = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model_wide, to_file='output/model_wide.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.fit(train_features, train_target, batch_size = 20, epochs=200,\n",
    "         validation_data=(validation_features, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 多输入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_A = train_features[:,:features_len//3]\n",
    "train_features_B = train_features[:,features_len//3:]\n",
    "validation_features_A = validation_features[:,:features_len//3]\n",
    "validation_features_B = validation_features[:,features_len//3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[features_len//3], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[features_len-features_len//3], name=\"deep_input\")\n",
    "hidden1_ = keras.layers.Dense(5, activation=\"selu\")(input_B)\n",
    "hidden2_ = keras.layers.Dense(3, activation=\"selu\")(hidden1_)\n",
    "concat_ = keras.layers.concatenate([input_A, hidden2_])\n",
    "output_ = keras.layers.Dense(1,activation='sigmoid')(concat_)\n",
    "model_combine = keras.Model(inputs=[input_A, input_B], outputs=[output_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model_combine,to_file='output/model_combine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.compile(loss = 'binary_crossentropy', metrics = 'accuracy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.fit([train_features_A, train_features_B],train_target,batch_size = 20, epochs=150,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir='output/logs',histogram_freq=1,embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combine.fit((train_features_A, train_features_B),train_target,batch_size = 20, epochs=200,\n",
    "                 validation_data=((validation_features_A,validation_features_B), validation_target),\n",
    "                  callbacks=tensorboard_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
